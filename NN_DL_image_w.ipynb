{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slotogram/Audio_seminar/blob/master/NN_DL_image_w.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdQJj_yVpUsc"
      },
      "source": [
        " <font size=\"6\">Нейронные сети</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данный ноутбук основан на материалах из курса по нейронным сетям ([ссылка](https://msu.ai/)) и содержит базовые понятия, связанные с нейронными сетями. \n",
        "\n",
        "Раздел 1 посвящен ознакомлению с многослойными нейронными сетями, принципам обучения нейронных сетей, а также концепциям, используемым в библиотеке PyTorch. Раздел 2 посвящен практическому применению многослойных сетей на примере задачи распознавания рукописных цифр. Разделы 3 и 4 посвящены сверточным нейронным сетям, а раздел 5 визуализации карт признаков в сверточных нейронных сетях.\n",
        "\n",
        "Раздел 1 не обязателен для ознакомления, но может быть полезен для изучения материала по нейросетям и для выполнения заданий. Разделы 2-5 необходимо выполнить для сдачи практического задания 3.5 в электронном курсе.\n",
        "\n",
        "Данный ноутбук можно выполнить с использованием среды выполнения без GPU, но c GPU ноутбук будет обучать нейронные сети быстрее (Меню Среда выполнения->Сменить среду выполнения->Аппаратный ускоритель->GPU)"
      ],
      "metadata": {
        "id": "IS5Z32KzUck-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NivMAPCwpUsq"
      },
      "source": [
        "#  1. Многослойные сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccxLbnmNpUsq"
      },
      "source": [
        "По мере развития мощности компьютеров, теоретической базы, появления больших датасетов и метода обратного распространения ошибки, появилась возможность строить более сложные сети - многослойные нейронные сети или же в современном понимании просто **нейронные сети**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiafoxBypUsq"
      },
      "source": [
        "Пример **полносвязной (fully connected network)** нейронной сети с двумя скрытыми слоями:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N-k3FWjpUsq"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/nn_fully_connected.png\"  width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY4PQXkdpUsq"
      },
      "source": [
        "##  Обучение нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmtF9C7PpUsq"
      },
      "source": [
        "Нейронная сеть в процессе **обучения** с учителем (англ. fit) последовательно (в определенном порядке)обрабатывает все объекты из обучающей выборки. Обучающая выборка может быть передана нейронной сети при обучении несколько раз и тогда одна полная экспозиция объектов из обучающей выборки называется **эпохой обучения**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVarEA-xpUsq"
      },
      "source": [
        "Обучающую выборку разделяют на две части: непосредственно использующуюся для обучения (анг. train) и тестовую (англ. test), на которой происходит оценка качества обучения. Стратегия разделения на train и test подвыборки может быть произвольной, но при разделении следует заботиться о том чтобы эти подвыборки были \"похожи\". В ходе обучения ошибка работы модели измеряется на train и test данных для контроля **переобучения** (англ. overfit). В случае возникновения переобучения нейронная сеть начинает терять обобщающую способность, что можно заметить по возникновению роста ошибки на тестовой подвыборке в ходе процесса обучения -- в случае переобучения нейронная сеть просто \"зазубривает\" примеры из обучающей подвыборки, а не аппроксимирует искомую функциональную зависимость между признаками и целевой переменной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytAEi26bpUsq"
      },
      "source": [
        "##  Прямое распространение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF81IKWPpUsr"
      },
      "source": [
        "Рассмотрим процесс **обучения с учителем** (анг. supervised learning) нейронной сети с прямым распространением сигнала (анг. Feedforward neural network). В ходе такого процесса мы хотим аппроксимировать при помощи нейронной сети функциональную зависимость между некоторым набором входных сигналов (признаков) и соответствующим им набором выходных сигналов (целевой переменной), используя множество эталонных пар входное значение - выходное значение. \n",
        "\n",
        "На этапе прямого распространения, нейронной сети на вход подаются сигналы для объектов из тренировочной выборки и при помощи **функции потерь** (анг. loss function) производится количественное сравнение полученных на выходе нейронной сети выходных сигналов с эталонными значениями. Далее, на этапе обратного распространения, данная информация будет использована для постройки параметров сети.\n",
        "\n",
        "Этап подстройки параметров нейронной сети может следовать после вычисления функции потерь при распространении сигнала от одного примера (online) или же после накоплении информации об отклике сети на пакете из нескольких примеров из обучающей выборки (**batch**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxJRWOj2pUsr"
      },
      "source": [
        "##  Веса сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPns13J0pUsr"
      },
      "source": [
        "**Нейрон** является базовым элементом строения нейронной сети. У нейрона есть определенное количество \"входов\", которыми он \"подключён\" к выходным значениям других нейронов. Нейрон осуществляет суммирование приходящих в него входных значений, причём учитывает значения входов с определенны весовыми коэффициентами (или просто **весами**), которые в определенном смысле характеризуют их значимость. Веса сети являются вещественными числами и могут быть как положительными, так и отрицательными. Именно веса нейрона являются изменяемыми параметрами и они подвергаются подстройке во время обучения нейронной сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdjvUeGLpUsr"
      },
      "source": [
        "###  Как вычислить результат работы нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bp9TWLHpUsr"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/nn__xor_example.png\"  width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksEHz1T5pUsr"
      },
      "source": [
        "Рассмотрим задачу классификации XOR, то есть на вход подадим 1 и 0, и будем ожидать 1 на выходе. Веса сети определим случайным образом:\n",
        "\n",
        "$I1=1\\quad I2=0$\n",
        "\n",
        "$w_1=0.45\\quad  w_2=0.78\\quad \n",
        "w_3=-0.12\\quad  w_4=0.13$\n",
        "\n",
        "\n",
        "$w_5=1.5\\quad  w_6=-2.3$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhb3s_e0pUsr"
      },
      "source": [
        "```python\n",
        "H1 = I1*W1+I2*W3 = 1*0.45+0*-0.12 = 0.45\n",
        "H2 = I1*W2+I2*W4 = 1*0.78+0*0.13 = 0.78\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_uBBs4PpUsr"
      },
      "source": [
        "Для того чтобы значения H1 и H2 не выходили за предельные значения, используется функция активации "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbJ08tn6pUsr"
      },
      "source": [
        "```python\n",
        "H1_out = sigmoid(H1) = sigmoid(0.45) = 0.61\n",
        "H2_out = sigmoid(H2) = sigmoid(0.78) = 0.69\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajmgHKwqpUsr"
      },
      "source": [
        "```python\n",
        "O1_in = 0.61*1.5+0.69*-2.3=-0.672\n",
        "O1_out = sigmoid(-0.672)=0.33\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOnxRbcwpUsr"
      },
      "source": [
        "Ответ нейронной сети O1_out = 0.33, а мы ожидали на выходе 1. О том, как скорректировать веса нужным образом будет рассказано в разделе о методе обратного распространения ошибки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZEKq2q6pUss"
      },
      "source": [
        "###  Смещение (bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4Pw28SdpUss"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/why_add_bias_example.png\"  width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0Gvo5XWpUss"
      },
      "source": [
        "Рассмотрим простой пример. На вход нейрона подаётся вес, умноженный на входное значение. После применения функции активации, в зависимости от веса, при всевозможных значениях входа мы можем получить следующие графики:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4klfJJ4ipUss"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L05/non_bias_problem_plot.png\"  width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D20LDDsXpUss"
      },
      "source": [
        "Но что если мы захотим чтобы при ```x=2``` чтобы сеть выводила ```0```, тогда без веса смещения эту задачу не решить.\n",
        "\n",
        "Просто изменить крутизну сигмоиды на самом деле не получится - вы хотите иметь возможность сдвинуть всю кривую вправо."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNcEd8_bpUss"
      },
      "source": [
        "**Смещение** (англ. bias) - это дополнительный коэффициент, прибавляющийся к сумме входов, наличие смещения позволяет сдвинуть функцию активации влево или вправо, что может иметь решающее значение для успешного обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxjfD2NrpUss"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/add_bias_example.png\"  width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F6TTYl1pUss"
      },
      "source": [
        "Тогда, при разных смещениях мы можем получить сдвинутые функции активации, что способствует лучшему обучению нейронной сети:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp41wQkopUss"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L05/after_add_bias_plot.png\"  width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLMJwafhpUss"
      },
      "source": [
        "##  Метод обратного распространения ошибки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJsP7L-bpUss"
      },
      "source": [
        "Итак, у нас есть все компоненты для обучения 2-х слойной модели:\n",
        "- предобработали данные\n",
        "- умножили их на веса\n",
        "- применили функцию активации\n",
        "- снова умножили\n",
        "- вычислили значение функции потерь\n",
        "- взяли градиент\n",
        "- обновили веса .... ?\n",
        "- оценили точность\n",
        "\n",
        "А как будем искать градиент?\n",
        "Можно вручную посчитать производную от функции потерь и весов. Но если модель поменяется, то придется делать это заново.\n",
        "\n",
        "Для того что бы упростить этот процесс используется формализм под названием \"Алгоритм обратного распространения ошибки\" или \"Backpropagation\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G7WJIDtpUst"
      },
      "source": [
        "**Метод обратного распространения ошибки (англ. backpropagation)** является эффективным методом вычисления градиента от функционала потерь многослойной нейронной сети. Благодаря данному методу становится практически возможным использование метода градиентного спуска для проведения процедуры обучения. Не смотря на то что первые работы по обучению многослойных перцептронов методом обратного распространения ошибки были опубликованы ещё в 1974 году, значительного развития данная технология получила сравнительно недавно, после появления современных вычислительных ресурсов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb09FU_bpUst"
      },
      "source": [
        "###  Основная идея метода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tGGl0GqpUst"
      },
      "source": [
        "Метод обратного распространения ошибки явно использует структуру многослойной нейронной сети как сложной функции, применяя цепное правило дифференцирования для вычисления градиента от функции потерь по весам сети. Градиент от функции потерь нейронной сети вычисляется последовательно, при движении по вычислительному графу нейронной сети от её выходов в направлении входов. Именно такой порядок обхода **вычислительного графа** и обуславливает название метода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elpZrN3bpUst"
      },
      "source": [
        "### Граф вычислений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmnJar8kpUst"
      },
      "source": [
        "Любую нейронную сеть можно представить в виде графа \"последовательных действий\", где результат вычисляется последовательно, одно действие за другим."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKsfbdUnpUst"
      },
      "source": [
        "Для простой модели вычислить производную вручную несложно.\n",
        "\n",
        "Однако по мере добавления слоев модель может оказаться намного сложнее. Например, так выглядит архитектура AlexNet:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyVrdBtQpUst"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/alexnet.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABIYusKspUst"
      },
      "source": [
        "Алгоритм обратного распространения ошибки позволяет находить градиенты для любого графа вычислений, если описываемая им функция дифференцируема.\n",
        "\n",
        "В его основе лежит правило взятия производной сложной функции (chain rule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9VQZWudpUst"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L05/chain_rule.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Fz63MjpUst"
      },
      "source": [
        "####  Пошаговый разбор метода обратного распространения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFNo-bgbpUst"
      },
      "source": [
        "Алгоритм, по которому вычисляются веса, можно представить в виде графа.\n",
        "\n",
        "А общее правило взятия градиентов можно представить следующим образом:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXLuuylQpUst"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/rule_for_taking_gradients.png\"  width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG55aUhhpUst"
      },
      "source": [
        "Рассмотрим следующую функцию:\n",
        "\n",
        "$$f(x,w)=\\frac{1}{1+e^{-(w_0x_0+w_1x_1+w_2)}}$$\n",
        "\n",
        "Её можно представить в виде простого графа вычислений:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8I56Jr-pUsu"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/graph_of_calculation_gradient.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOj3G1dypUsu"
      },
      "source": [
        "На примере данной несложной функции рассмотрим алгоритм обратного распространения ошибки и найдём величину её градиента по параметрам $w$.\n",
        "Нам потребуется вычислить частные производные $\\frac{\\partial f}{\\partial w_0}$, $\\frac{\\partial f}{\\partial w_1}$, $\\frac{\\partial f}{dw_2}$, $\\frac{\\partial f}{\\partial x_0}$ и $\\frac{\\partial f}{\\partial x_1}$. \n",
        "\n",
        "Пусть \"веса\" $w$ инициализированы значениями $w_0=2\\;w_1=-3,\\;w_2=-3,$а \"входные признаки\" $x$ принимают значения $x_0=-1.0,\\;x_1=-2.0$.\n",
        "\n",
        "Делая прямой проход через граф вычислений для данной функции, получаем её значение для заданных $w$ и $x$ равным $f=0.73$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aooG1xM7pUsu"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/forward_pass_example.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qdzsQhQpUsu"
      },
      "source": [
        "Далее, в соответствии с алгоритмом обратного распространения ошибки, рассчитаем частные производные, пройдясь последовательно по графу вычислений, постепенно накапливая искомое значение для градиента функции:\n",
        "\n",
        "Для начала посчитаем производную функции $\\frac{\\partial f}{\\partial f}$, которая будет равна единице. Движемся дальше по графу вычислений &mdash; следующая вершина содержит функцию $f(x)=\\frac{1}{x}$, производная которой равна $\\frac{df}{dx}=-\\frac{1}{x^2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKNqkgeQpUsu"
      },
      "source": [
        "\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/compute_gradient_1_step.png\"  width=\"800\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF5O-aQzpUsu"
      },
      "source": [
        "В следующем узле находится функция $f(x)=1+x$. Производная от константы $+1$ нулю, то есть производная от производная всего выражения в данном узле равняется просто $\\frac{df}{dx}=1$:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/compute_gradient_2_step.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWpK8PrmpUsu"
      },
      "source": [
        "Третья вершина содержит экспоненту $f(x)=e^x$. Её производная также является экспонентой $\\frac{df}{dx}=e^x$:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/compute_gradient_3_step.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlt0GrbtpUsu"
      },
      "source": [
        "Следующая вершина, четвертая, содержит умножение на константу $f(x)=ax$. Производная равна $\\frac{df}{dx}=a$:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/compute_gradient_4_step.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN4vlQ6SpUsu"
      },
      "source": [
        "Двигаясь по графу вычислений мы дошли до узла суммирования, который имеет два входа. Относительно каждого из входов локальный градиент в вершине суммирования будет равен $1$. Так как умножение на единицу не изменит значения входного градиента, всем входам узла суммирования мы можем приписать точно такое же значение входного градиента ($0.2$), что мы имели и для самого узла суммирования. Будем действовать аналогично и со всеми остальными узлами суммирования, что встретятся нам в вычислительном графе.\n",
        "\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/compute_gradient_5_step.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVgtWDDdpUsu"
      },
      "source": [
        "Двигаясь далее к началу графа вычислений мы подходим к вершинам умножения. Для такой вершины локальный градиент по отношению к какому-либо из входов просто равен значению оставшегося входа, умноженным на входящий градиент. Точно так же мы можем поступить и с оставшейся второй вершиной умножения, которая привязана к $w_1$ и $x_1$:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/compute_gradient_6_step.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_B96A7apUsu"
      },
      "source": [
        "Так, двигаясь по графу вычислений в обратном направлении от выхода сети к входным признакам, мы последовательно для каждого узла умножаем локальный градиент на входящий градиент, используя цепное правило дифференцирования сложной функции. В описанном примере мы полностью разбили граф вычислений на отдельные элементарные узлы. Разбиение вычислительного графа на элементарные узлы вовсе не обязательно -- мы можем сгруппировать несколько вершин вместе, если они образуют дифференцируемую функцию и рассматривать их совместно.  \n",
        "\n",
        "Так, в нашем примере, мы можем заметить что вычислительный граф можно свести к двум операциям: получению выражения $w_0x_0+w_1x_1+w_2$ и последующему вычислению от него сигмоидельной функции. Важно отметить, что сигмоида обладает важным свойством: её производная может быть выражена через саму сигмоидалную функцию:\n",
        "\n",
        "$$\\frac{d\\sigma{(x)}}{dx}=(1-\\sigma{(x)})\\sigma{(x)}$$\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/compute_gradient_join_vertices_sigmoid_example.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRztMNnfpUsv"
      },
      "source": [
        "В коде, без использования библиотек подсчёт градиентов можно записать как:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epCv9VgrpUsv"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/calculating_gradients_in_code.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhqUAO_cpUsv"
      },
      "source": [
        "#### Более сложные случаи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13eOzyjlpUsv"
      },
      "source": [
        "#####  Обратное распространение для векторов:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py6VIYvUpUsv"
      },
      "source": [
        "В случае, когда выход сети $z$ не один (многоклассовая классификация, тексты, картинки и тд.), необходимо учитывать значения каждого элемента выходного вектора, для расчёта градиентов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwHLOPIpUsv"
      },
      "source": [
        "Матрица Якоби — матрица, составленной из частных производных отображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DiRDzDtpUsv"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/backpopagation_with_vectors.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmHA2LtUpUsv"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/backpropagation_with_vectors_example.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbBzjWQ4pUsv"
      },
      "source": [
        "##### Множественная вершина"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pcFn2qIpUsv"
      },
      "source": [
        "Если вход соединен с несколькими вершинами графа или у вершины больше одного выхода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPVbFi3gpUsv"
      },
      "source": [
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/multiple_vertices_of_graph.png\"  width=\"700\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNI0jyPppUsv"
      },
      "source": [
        "То в месте ветвления можно создать дополнительную вершину, которая будет соответствовать операции копирования."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MhPv5pIpUsv"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/add_copy_operation_for_vertex.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB3F4845pUsv"
      },
      "source": [
        "Тогда при обратном распространении, градиент можно разделить в соответствии с осуществлённой операцией"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK1hHbY0pUsv"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/upstream_gradient.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_ESF_ejpUsw"
      },
      "source": [
        "Для базовых операций можно выделить следующие шаблоны \"разделения\" градиента:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87SDobKWpUsw"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/add_copy_mul_max_gates.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN7PuAKhpUsw"
      },
      "source": [
        "####  Анимация работы метода обратного распространения ошибки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibJazqvypUsw"
      },
      "source": [
        "\n",
        "\n",
        "Таким образом, метод обратного распространения ошибки включает в себя следующие шаги:\n",
        "* Forward propagation (FP) - прямое распространение сигнала от входа к выходам (без которого не получить вычисленные значения в графе).\n",
        "* Back propagation (BP) - расчёт величины градиента от выхода ко входам.\n",
        "* Обновление весов, в зависимости от величины градиента. На анимации буквой $\\eta$ обозначен learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQZhfr4ApUsw"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L05/backprop_animation.gif\"  width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YQoDGRupUsw"
      },
      "source": [
        "#### Введение в PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLzb1xgppUsw"
      },
      "source": [
        "В данном практическом модуле работа будет осуществляться с испольованием [PyTorch](https://pytorch.org/), поэтому необходимо познакомиться с основными концептами, принципами и функциями PyTorch.\n",
        "\n",
        "Лучший друг в этом, конечно же, [документация](https://pytorch.org/docs/stable/index.html), однако можно привести основные моменты этой библиотеки/фреймворка:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiH9KMY9pUsw"
      },
      "source": [
        "##### Основная сущность - torch.tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQLWniy4pUsw"
      },
      "source": [
        "Поскольку основная сущность, с которой мы работаем, это вектора и матрицы, то для них нужен очень мощный и функциональный класс - [torch.Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)\n",
        "\n",
        "Пустой класс тензора:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbFU7_lGpUsw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "a = torch.Tensor() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iauETA6opUsw"
      },
      "source": [
        "Конструктор класса с заполнением существующими значениями:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfnhrO6QpUsw"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([1.1, 2.2, 3.2]) \n",
        "a.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7yh_VQ8pUsx"
      },
      "source": [
        "Явное указание типа данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InW1wuLBpUsx"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([1.1, 2.2, 3.2], dtype=torch.float64)\n",
        "a.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FceI7JbApUsx"
      },
      "source": [
        "Создание 2-мерного тензора, заполненного единицами (для нулей zeros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ih_ZsOVpUsx"
      },
      "outputs": [],
      "source": [
        "a = torch.ones(size=(3, 2)) \n",
        "a.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y0TOLwnpUsx"
      },
      "source": [
        "Создание 2-мерного тензора, заполненного нашим значением\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA4OhkhZpUsx"
      },
      "outputs": [],
      "source": [
        "a = torch.full((3, 2), 5.1) \n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlvTTBAopUsx"
      },
      "source": [
        "Транспонирование (изменение порядка осей)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQnFAuJ4pUsx"
      },
      "outputs": [],
      "source": [
        "a = a.T \n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjk1dowWpUsx"
      },
      "source": [
        "В библиотеке доступно огромное количество встроенных математических примитивов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTDzJu_zpUsx"
      },
      "outputs": [],
      "source": [
        "c = torch.atan2(a[0], a[1]) \n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svbxxxyVpUsx"
      },
      "source": [
        "Почти всё, что есть в numpy, есть в pytorch, например sum():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtaC1qu-pUsx"
      },
      "outputs": [],
      "source": [
        "c.sum() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27oKm4iEpUsy"
      },
      "source": [
        "Добавление и удаление осей "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8QaF8lmpUsy"
      },
      "outputs": [],
      "source": [
        "a = torch.zeros((2, 5, 1, 8))\n",
        "print(\"Original tensor size:\\n\", a.size())\n",
        "\n",
        "a = a.permute(dims=(2, 0, 3, 1)) # перестановка измерений\n",
        "print(\"After permute tensor size:\\n\", a.size())\n",
        "\n",
        "a = a.squeeze() # удаление единичных измерений из тензора\n",
        "print(\"After squzee tensor size:\\n\", a.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxSM8Jz_pUsy"
      },
      "source": [
        "Преобразование torch.tensor в numpy массив"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18gfYO6cpUsy"
      },
      "outputs": [],
      "source": [
        "a.numpy() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyGcjq9BpUsy"
      },
      "source": [
        "PyTorch позволяет тензору быть представлением существующего тензора. Тензор представления использует те же базовые данные, что и его базовый тензор. Поддержка `view` позволяет избежать явного копирования данных, что позволяет нам выполнять быстрое и эффективное изменение формы, нарезку и операции с элементами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFK8iNfIpUsy"
      },
      "outputs": [],
      "source": [
        "a = torch.rand(2, 8)\n",
        "print(\"Original tensor:\\n\", a)\n",
        "b = a.view(4, 4) # подобные трансформации лучше не делать со структурированными данными (например, изображениями)\n",
        "print(\"Tensor after view tensor:\\n\", b)\n",
        "b += 1\n",
        "print(\"Add 1 to tensor:\\n\", b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFtuGUQtpUsy"
      },
      "source": [
        "Размещение тензора на GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otBzXq7ZpUsy"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Cuda available: \", torch.cuda.is_available(), '\\n')\n",
        "a = a.to(device) # tensor to gpu\n",
        "b = torch.full_like(a, 2).to(device)\n",
        "c = a * b # compute on gpu (more fast with parallel computing)\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NggPRKUqpUsy"
      },
      "source": [
        "##### Автоматическое вычисление градиентов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG6POgkQpUsy"
      },
      "source": [
        "Torch умеет запоминать последовательность операций с нашими тензорами и вычислять градиент."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U7rxnxZpUsy"
      },
      "outputs": [],
      "source": [
        "x_train = torch.tensor([1., 2., 3., 4.])\n",
        "y_train = torch.tensor([2., 4., 6., 8.])\n",
        "\n",
        "W = torch.tensor(1.0, requires_grad=True) \n",
        "\n",
        "print (f\"W.grad = {W.grad} (before forward pass must be 'None')\")\n",
        "\n",
        "y_pred = W * x_train\n",
        "criterion = torch.nn.MSELoss()\n",
        "MSE = criterion(y_pred, y_train)\n",
        "print(f\"MSE = {MSE}\")\n",
        "\n",
        "# backward pass to compute gradient dMSE/dw\n",
        "MSE.backward()\n",
        "print (f\"W.grad = {W.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyAedbDCpUsy"
      },
      "source": [
        "Отсоединение тензора от графа вычислений (используйте при копировании тензора)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsPfkbWlpUsz"
      },
      "outputs": [],
      "source": [
        "W.detach() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTIRLm1RpUsz"
      },
      "source": [
        "##### Другие интересные подмодули фреймворка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrRfp0xBpUsz"
      },
      "source": [
        "\n",
        "Torch\n",
        "\n",
        "* ```torch.nn``` - Модуль для работы с нейронными сетями в стиле ООП\n",
        "* ```torch.nn.functional``` - То же, что выше, но в функциональном стиле\n",
        "* ```torch.utils.data``` - Создание датасета, даталоадера\n",
        "* ```torch.linalg``` - Линейная алгебра\n",
        "* ```torch.fft``` - Преобразования Фурье\n",
        "* ```torch.random``` - Рандом\n",
        "\n",
        "\n",
        "Torchvision - работа с изображениями\n",
        "* ```torchvision.transforms``` - Трансформации для изображений\n",
        "* ```torchvision.datasets``` - Учебные датасеты, трансформации\n",
        "* ```torchvision.models``` - Готовые нейронки для изображений\n",
        "\n",
        "Torchaudio - работа с аудио.\n",
        "* Подмодули для аудио\n",
        "\n",
        "Torchtext - работа с текстом.\n",
        "* Подмодули для текста\n",
        "\n",
        "etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX1jRHj2pUsz"
      },
      "source": [
        "####  Обратное распространение ошибки в PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB9GfWzJpUsz"
      },
      "source": [
        "Рассмотрим пример реализации шага обратного прохода на примере вычисления квадрата ошибки для линейной регрессии (для простоты не будем рассматривать смещение):\n",
        "\n",
        "$$y=w\\cdot x, \\quad при \\;x=[1,2,3,4],\\;y=[2,4,6,8],\\;w=1$$\n",
        "\n",
        "В данном примере видно, что предсказанный моделью $\\hat{y}=[1,2,3,4]$ не совпадает с истинными значениями $y$, и соответственно квадратичная ошибка для такого примера будет $$MSE=\\frac{1}{4}\\sum_{i=1}^4E_i^2=\\frac{1}{4}\\sum_{i=1}^4(\\hat{y}_i-y_i)^2=\\frac{1+4+9+16}{4}=7.5$$\n",
        "\n",
        "Градиент весов $w$ вычисляется следующим образом, в соответствии с chain rule:\n",
        "\n",
        "$$\\frac{d MSE}{d w} = \\frac{\\partial MSE}{\\partial E}\\cdot \\frac{\\partial E}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial w}$$\n",
        "\n",
        "Рассчитаем его с использованием PyTorch:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goIPRNstpUsz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "# Этот параметр мы хотим оптимизировать -> requires_grad=True\n",
        "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
        "print (f\"W.grad = {W.grad} (before forward pass must be 'None')\\n\")\n",
        "# прямое распространение, чтобы расчитать MSE\n",
        "y_pred = W * x_train\n",
        "E = y_pred - y_train\n",
        "SE = E ** 2\n",
        "MSE = SE.mean()\n",
        "print(f\"MSE = {MSE}\")\n",
        "\n",
        "# обратное распространение, чтобы посчитать градиент dMSE/dw\n",
        "MSE.backward()\n",
        "print (f\"W.grad = {W.grad}\")\n",
        "print (f\"E.grad = {E.retain_grad()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n-MJLV-pUsz"
      },
      "source": [
        "В данном примере мы произвели следующие расчеты:\n",
        "\n",
        "$\\frac{\\partial MSE}{\\partial E}=\\frac{\\sum\\partial E^2}{\\partial E}=\\frac{1}{4}\\cdot2\\cdot E=\\frac{1}{2}*[-1, -2, -3, -4]=[-0.5, -1, -1.5, -2]\\quad *-поэлементное\\;умножение$\n",
        "\n",
        "$\\frac{\\partial E}{\\partial \\hat{y}}=\\frac{\\partial (\\hat{y}-y)}{\\partial \\hat{y}}=1$\n",
        "\n",
        "$\\frac{\\partial \\hat{y}}{\\partial w}=\\frac{\\partial wx}{\\partial w}=x=[1, 2, 3, 4]$\n",
        "\n",
        "$\\frac{d MSE}{d w} = \\frac{\\partial MSE}{\\partial E}\\cdot \\frac{\\partial E}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial w}=\\sum[-0.5, -1, -1.5, -2]*[1, 2, 3, 4]=-0.5-2-4.5-8=-15$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vb4X_eypUsz"
      },
      "source": [
        "`MSE.backward()` автоматически вычисляет градиент $\\frac{dMSE}{dw}$ при указании `requires_grad=True`. \n",
        "Результаты вычислений будут храниться в `W.grad`. Для всех промежуточных переменных градиенты не сохраняются, поэтому попытка обратиться, например, к `E.grad` выдает `None`. \n",
        "\n",
        "Также после однократного обратного прохода, в целях экономии памяти, граф, используемый для вычисления градиента, будет удаляться и следующий запуск `MSE.backward()` будет выдавать ошибку:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1gKsji9pUsz"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "MSE.backward() # Error on second backward call\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfE0nkpapUsz"
      },
      "source": [
        "Чтобы сохранить вычислительный граф, для аргумента `retain_graph` функции `backward()` нужно указать значение `True`. Также может быть полезным сохранять значения градиентов для промежуточных переменных, это делается с помощью функции `tensor.retain_grad()`. В таком случае, значения градиентов, полученные на следующих итерациях обратного распространения ошибки, будут складываться с текущими значениями градиентов.\n",
        "\n",
        "Градиенты переменных, для которых был указан `retain_graph=True` сохраняются автоматически, чтобы избежать их накопления при многократном итерировании алгоритма обратного распространения, нужно обнулять градиент на каждом шаге с помощью функции `tensor.grad.zero_()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqv7KebdpUs0"
      },
      "outputs": [],
      "source": [
        "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "# Этот параметр мы хотим оптимизировать -> requires_grad=True\n",
        "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# прямое распространение, чтобы расчитать MSE\n",
        "y_pred = W * x_train\n",
        "E = y_pred - y_train\n",
        "E.retain_grad() # Сохраняем градиенты во временный тензор E\n",
        "SE = E**2\n",
        "MSE = SE.sum().div(4)\n",
        "\n",
        "print(\"========== Backprop 1 ==============\")\n",
        "MSE.backward(retain_graph=True)\n",
        "print (f\"dMSE/dE = {E.grad}\")\n",
        "print (f\"dMSE/dW = {W.grad}\")\n",
        "\n",
        "print(\"========== Backprop 2 ==============\")\n",
        "MSE.backward(retain_graph=True)\n",
        "# Gradients are accumulated\n",
        "print (f\"dMSE/dE = {E.grad}\")\n",
        "print (f\"dMSE/dW = {W.grad}\")\n",
        "\n",
        "print(\"========== Backprop 3 ==============\")\n",
        "W.grad.zero_() # Обнуляем градиенты для W для выполнения следующей итерации\n",
        "MSE.backward(retain_graph=True)\n",
        "# Градиенты для W не накапливаются, но для E сохраняются\n",
        "print (f\"dMSE/dE = {E.grad}\")\n",
        "print (f\"dMSE/dW = {W.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm5w6SXfpUs0"
      },
      "source": [
        "Итак, мы умеем вычислять градиент $\\frac{\\partial MSE}{\\partial w}$ для нашего примера. Теперь давайте с его помощью оптимизируем веса, используя алгоритм обратного распространения ошибки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIF31XzypUs0"
      },
      "outputs": [],
      "source": [
        "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y_tain = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# Зададим выход модели\n",
        "def forward(x_train):\n",
        "    return W * x_train\n",
        "\n",
        "# Зададим MSE loss \n",
        "def criterion(y_pred, y_train):\n",
        "    return ((y_pred - y_train)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(x) = {forward(x_train)}')\n",
        "print(f'True values: y = {y_train}\\n')\n",
        "\n",
        "# Обучение\n",
        "learning_rate = 0.005\n",
        "num_epochs = 102\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Прямое распространение\n",
        "    y_pred = forward(x_train)\n",
        "\n",
        "    # Вычисляем MSE loss\n",
        "    MSE = criterion(y_pred, y_train)\n",
        "\n",
        "    # Обратное распространение, вычисляем градиенты\n",
        "    MSE.backward()\n",
        "\n",
        "    # Обновляем веса\n",
        "    with torch.no_grad(): #  Мы не хатим, чтобы шаг обновления весов был частью вычислительного графа\n",
        "        W -= learning_rate * W.grad \n",
        "    \n",
        "    # Зануляем градиенты после обновления весов, чтобы их значения не накапливались\n",
        "    W.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 1:\n",
        "        print(f'epoch {epoch}: w = {W.item():.3f}, loss = {MSE.item():.8f}')\n",
        "\n",
        "print(f'\\nPrediction after training: f(x) = {forward(x_train)}')\n",
        "print(f'True values: y = {y_train}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9A3FWp9pUs0"
      },
      "source": [
        "Видно, что наш подход позволяет оптимизировать вес $w$ регрессии из примера и таким образом добиться почти идеального предсказания нашей модели, однако в данном подходе дополнительно можно автоматизировать вычисление функции потерь и обновление параметров с учетом градиента, используя готовые функции потерь из `torch.nn` и оптимизаторы из `torch.optim`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7S6484spUs0"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y_tain = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# Зададим выход модели\n",
        "def forward(x_train):\n",
        "    return W*x_train\n",
        "\n",
        "\n",
        "print(f'Prediction before training: f(x) = {forward(x_train)}')\n",
        "print(f'True values: y = {y_train}\\n')\n",
        "\n",
        "# Обучение\n",
        "learning_rate = 0.005\n",
        "num_epochs = 102\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([W], lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "# Прямое распространение\n",
        "    y_pred = forward(x_train)\n",
        "\n",
        "    # Вычисляем MSE loss\n",
        "    MSE = criterion(y_pred, y_train)\n",
        "\n",
        "    # Обратное распространение, вычисляем градиенты\n",
        "    MSE.backward()\n",
        "\n",
        "    # Обновляем веса\n",
        "    optimizer.step()\n",
        "\n",
        "    # Зануляем градиенты после обновления весов, чтобы их значения не накапливались\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 1:\n",
        "        print(f'epoch {epoch}: w = {W.item():.3f}, loss = {MSE.item():.8f}')\n",
        "\n",
        "print(f'\\nPrediction after training: f(x) = {forward(x_train)}')\n",
        "print(f'True values: y = {y_train}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5Ktyb50pUs0"
      },
      "source": [
        "###  Преимущества и недостатки метода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41yI11rvpUs0"
      },
      "source": [
        "В настоящее время метод обратного распространения ошибки фактически стал стандартом при обучении широкого спектра современных архитектур нейронных сетей. Этот метод даёт итерационное решение задачи поиска минимума функционала ошибки, последовательно подстраивая веса нейронной сети в ходе обучения. К сожалению, такой подход не гарантирует что в ходе обучения нейронной сети мы действительно достигнем абсолютного минимума функции потерь. Кроме того, в силу итерационной природы алгоритма, для обучения может потребоваться огромное количество циклов, что иногда приводит к необходимости проводить вычисления непрерывно в течении дней, недель или даже месяцев. Остановимся ещё на некоторых трудностях, которые могут сопровождать метод обратного распространения ошибки:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCjjFOLKpUs0"
      },
      "source": [
        "* Остановка обучения в локальном минимуме функции потерь\n",
        "\n",
        "    На функцию потерь нейронной сети можно смотреть как на определенную поверхность в пространстве высокой размерности (размерность пространства соответствует числу весов нейронной сети). Скажем, если бы у нейронной сети было всего два веса, то такая поверхность была бы похожа на земной рельеф.\n",
        "\n",
        "    Поверхность функции потерь во всех возникающих на практике случаях достаточно сложна и содержит высокоразмерные аналоги холмов, впадин, долин и всевозможных их комбинаций. Применяя градиентный спуск, мы фактически движемся по такой поверхности в направлении самого \"крутого\" склона вниз, начиная своё движение из какой-то фиксированной точки поверхности. Может так оказаться, что мы начали своё движение по поверхности неподалёку от небольшой впадины (локального минимума функции потерь) и, \"закатившись\" в него, не сможем больше из него выбраться, даже если совсем неподалёку в пространстве весов сети будет присутствовать значительно более \"глубокий\" минимум -- все пути из неглубокого локального минимума находятся в направлении противоположном тому, согласно которому мы движемся при методе градиентного спуска. Чтобы \"выпрыгнуть\" из такого нежелательного локального минимума, может потребоваться кратковременно увеличить скорость обучения (фактически размер шага). Проблема выбора алгоритма задания оптимального шага обучения во время градиентного спуска в общем случае не решена."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_HpVFzepUs0"
      },
      "source": [
        "* Паралич сети\n",
        "\n",
        "    Пусть мы обучаем многослойную нейронную сеть, в которой к качестве функции активации нейронов используются сигмоидельные функции (логистическая функция или tanh(x)). Если мы допустим слишком сильное обновление весов у большого числа нейронов, чего можно легко добиться выбором слишком большой величины скорости (шага) обучения, то дальнейшее обучение сети фактически может остановиться. Дело в том, что в области больших по модулю значений аргумента сигмоидальной функция практически не изменяется, а значит её производная слабо отличается от нуля. Так как величина обновления весов на следующем шаге градиентного спуска будет пропорциональная значением этих производных, то оно также будет близко к нулю. Такой переход нейронов в \"насыщение\" может быть уже необратимым и методу градиентного спуска потребуется неограниченно много времени для возвращения сети в исходное \"рабочее\" состояние."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2o7tSmRpUs0"
      },
      "source": [
        "##  Функции потерь (loss functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lauYxfipUs1"
      },
      "source": [
        "Предположим, у нас есть нейронная сеть с некоторыми весами, прежде всего мы должны понять, насколько она точна - то есть наши ожидания соответствуют результату работы нейронной сети. Мы подали на вход нейронной сети изображение, сигналы прошли через наши слои и функции активации вперёд **(forward propagation)**, и на выходе мы имеем некоторый ответ. Как его оценить? Насколько он точен?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT4KlbWhpUs1"
      },
      "source": [
        "Для оценки соответствия полученного результата ожидаемому, используют функции потерь (loss function). Значение функции потерь даёт количественную оценку величины такого соответствия."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_4co632pUs1"
      },
      "source": [
        "Функция потерь в нейронной сети принимает два аргумента:\n",
        "* вектор значений, который мы считаем априорно верным\n",
        "* вектор значений конечных выходов модели, который должен соответствовать априорно верному\n",
        "\n",
        "Важно заметить, что для успешного обучения модели методом градиентного спуска мы должны потребовать от функции потерь дифференцируемости и ограниченности снизу.\n",
        "\n",
        "[PyTorch Docs](https://pytorch.org/docs/stable/nn.html#loss-functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-xtdTIspUs1"
      },
      "source": [
        "###  Mean squared error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTQiYoD8pUs1"
      },
      "source": [
        "Mean Squared Error (MSE) - это средняя квадратическая ошибка. Данная функция потерь очень популярная, поскольку она проста для понимания и реализации, и в целом работает довольно хорошо. Чтобы рассчитать MSE, вы берете разницу между предсказаниями вашей модели и фактическими значениями, вычитаете их, возводя разницу в квадрат и затем усредняете по всему набору данных.\n",
        "Результат всегда положительный, независимо от знака предсказанных и истинных значений, и идеальное значение равно 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smyYt0WwpUs1"
      },
      "source": [
        "$$MSE=\\frac{1}{n}\\sum_{i=1}^n(Y_i - \\hat{Y_i})^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGGJJDICpUs1"
      },
      "source": [
        "```python\n",
        "torch.nn.MSELoss()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w42oEB2pUs1"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "input_values = torch.Tensor([0.5, -0.25, 0.75])\n",
        "print(f'input_values: {input_values}')\n",
        "target = torch.Tensor([1, 0.25, 0.25])\n",
        "print(f'target: {target}')\n",
        "loss_mse = criterion(input_values, target)\n",
        "print(f'loss_mse: {loss_mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzjwE261pUs1"
      },
      "source": [
        "* **Преимущество:** Использование MSE в качестве функции потерь даёт основания ожидать, что обученная с ней модель не имеет сильных \"выбросов\" в величине ошибки. Любой большой выброс в невязке $|Y_i - \\hat Y_i| \\ggg 0 $ при вычислении MSE был бы возведён в квадрат и дал бы вовсе огромный вклад в итоговое значение функции потерь.\n",
        "\n",
        "\n",
        "* **Недостаток:** Как логично следует из описанного выше преимущества  MSE, данная функция потерь в первую очередь сильно штрафует модель за наличие выбросов в предсказаниях.  Для ряда практически важных задач, тем не менее, важнее оказывается наиболее высокая точность работы на абсолютном большинстве входных примеров, нежели отсутствие одиночных выбросов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBSuVdq7pUs1"
      },
      "source": [
        "###  Mean Absolute Error "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9VEPNTbpUs1"
      },
      "source": [
        "Средняя абсолютная ошибка (MAE) -- это величина, которая измеряет среднюю по всем образцам величину невязки $|Y_i - \\hat{Y_i}|$. Не смотря на то что определение этой функции потерь похоже на MSE (MSE loss можно назвать $L_2$ ошибкой, а MAE в этом смысле можно назвать $L_1$ ошибкой), средняя абсолютная ошибка имеет существенно другие свойства. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gCLMnVwpUs1"
      },
      "source": [
        "$$MAE=\\frac{1}{n}\\sum_{i=1}^n|Y_i - \\hat{Y_i}|$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpSct-xpUs2"
      },
      "source": [
        "```python\n",
        "torch.nn.L1Loss()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzDL8dfnpUs2"
      },
      "outputs": [],
      "source": [
        "criterion = nn.L1Loss()\n",
        "input_values = torch.Tensor([0.5, -0.25, 0.75])\n",
        "print(f'input_values: {input_values}')\n",
        "target = torch.Tensor([1, 0.25, 0.25])\n",
        "print(f'target: {target}')\n",
        "loss_mae = criterion(input_values, target)\n",
        "print(f'loss_mae: {loss_mae}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGb9r4mKpUs2"
      },
      "source": [
        "* **Преимущество:** Поскольку при вычислении MAE мы считаем абсолютное значение ошибки, данная метрика не придёт такого большого значения \"выбросам\", как MSE -- все ошибки учитываются равнозначно в единой линейной шкале.\n",
        "\n",
        "\n",
        "* **Недостаток:**  Недостаток применения MAE в качестве функции потерь при обучении модели напрямую вытекает из преимуществ. Обученная с MAE модель может показывать хорошие (или даже отличные) результаты в большинстве случае, но на отдельных примерах допускать большую ошибку. Если специфика решаемой задачи не позволяет нам пренебречь такими одиночными большими выбросами, то следует воздержаться от применения данной метрики."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOZc3wrMpUs2"
      },
      "source": [
        "###  Cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90KVezu0pUs2"
      },
      "source": [
        "Кроссэнтропия (перекрёстная энтропия) является одной из наиболее часто применимых в практике обучения нейронных сетей функцией потерь. С точки зрения теории информации кроссэнтропия между двумя вероятностными распределениями $p$ и $q$ над одним и тем же вероятностным пространством определяет среднее количество информации (измеренное в количестве бит), необходимое для идентификации одиночного события из вероятностного пространства, если информация о таком событии записывается в виде оптимизированного под \"оценочное\" распределение $q$, нежели чем с использованием \"истинного\" распределения $p$.\n",
        "\n",
        "Интуитивно кроссэнетропию можно понимать в качестве меры близости \"оценочного\" распределения $q$ к истинному распределению $p$. На практике элементами распределения $p$ является набор ground true значений из обучающей выборки, а элементы оценочного распределения $q$ являются выводами используемой нами модели.\n",
        "\n",
        "Формально кроссэнтропию можно записать в виде:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKM53cjOpUs2"
      },
      "source": [
        "$$ H(p,q) = -E_p[\\log q]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p08f6mghpUs2"
      },
      "source": [
        "Где:\n",
        "* $E_p$ - оператор математического ожидания относительно распределения $p$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lipaKtzpUs2"
      },
      "source": [
        "Однако чаще кроссэнтропию определяют с помощью энтропии и расстояния Кульбака-Лейблера:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5nkSJDYpUs2"
      },
      "source": [
        "$$H(p,q) = H(p) +D_{KL}(p||q)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kTbEVBCpUs2"
      },
      "source": [
        "В случае нейронных сетей, где вероятности представлены дискретными выходами, формула превращается в:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAt0Ahw7pUs2"
      },
      "source": [
        "$$H(p,q)=-\\sum_xp(x)\\log q(x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqbM1O_QpUs2"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/probabiliry_cross_entropy.png\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scvy4ej1pUs2"
      },
      "source": [
        "\n",
        "\n",
        "Поскольку чаще всего кроссэнтропию используют после softmax, то в готовых реализациях softmax объединяют с кроссэнтропией"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f6Exjp0pUs2"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/softmax_with_cross_entropy.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buNIEm3mpUs2"
      },
      "source": [
        "CrossEntropyLoss из torch включает в себя Softmax!\n",
        "```python\n",
        "torch.nn.CrossEntropyLoss()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKLxRjnlpUs3"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "input_values = torch.rand(3, 3)\n",
        "print(f'input_values: {input_values}')\n",
        "target = torch.empty(3, dtype=torch.long).random_(3)\n",
        "print(f'target: {target}')\n",
        "loss_ce = criterion(input_values, target)\n",
        "print(f'loss_ce: {loss_ce}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzhQqDWBpUs3"
      },
      "source": [
        "* **Преимущества:** Важное свойство кроссэнтропии - возможность работать с весами для классов. А значит и возможность применения этой функции потерь при работе с несбалансированным датасетом.\n",
        "* **Недостатки:** Вычислительная сложность выше, чем MSE или MAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u55hQo4ApUs3"
      },
      "source": [
        "###  Binary cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkSCl7lUpUs3"
      },
      "source": [
        "В частном случае, когда количество классов равно двум, и их можно закодировать одним числом: 0 - для первого класса, и 1 для второго, то формулу CrossEntropyLoss можно адаптировать для этого случая:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okB6oJLupUs3"
      },
      "source": [
        "$$H_p(q)=-\\frac{1}{N}\\sum_{i=1}^N y_i\\cdot log(p(y_i))+(1-y_i)\\cdot log(1-p(y_i))$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDOjNcMlpUs3"
      },
      "source": [
        "\n",
        "        torch.nn.BCELoss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3IoGJpFpUs3"
      },
      "source": [
        "Важной особенностью BCELoss является то, что она ждёт одно число выхода сети и одно число как верный результат. Тут используется не one-hot кодировка для двух классов, а **одно число 0 - первый класс, 1 - второй класс.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owlvNRhnpUs3"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "input_values = torch.rand(1)\n",
        "print(f'input_values: {input_values}')\n",
        "target = torch.empty(1).random_(2)\n",
        "print(f'target: {target}')\n",
        "loss_bce = criterion(input_values, target)\n",
        "print(f'loss_bce: {loss_bce}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZK9ehbvpUs3"
      },
      "source": [
        "Если классы \"абсолютно полностью\" не совпали, то возникает ситуация взятия логарифма от 0, а он не определён и стремится к бесконечности, поэтому берётся \"обрезанная бесконечность\" равная 100.\n",
        "\n",
        "Далее, если сэмплов несколько, то по умолчанию берётся среднее по семплам. См. аргумент `reduction`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXStXGKQpUs3"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "input_values = torch.ones((5))\n",
        "print(f'input_values: {input_values}')\n",
        "target = torch.zeros(5)\n",
        "print(f'target: {target}')\n",
        "loss_bce = criterion(input_values, target)\n",
        "print(f'loss_bce: {loss_bce}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPKMLDVtpUs3"
      },
      "source": [
        "###  Итоги\n",
        "\n",
        "Кросс-энтропия предпочтительнее для *классификации*, в то время как среднеквадратичная ошибка является одним из лучших вариантов для *регрессии*. Это происходит непосредственно из самой постановки задач &mdash; в классификации вы работаете с очень конкретным набором возможных выходных значений, поэтому MSE плохо определен (поскольку он не обладает такого рода знаниями, поэтому наказывает ошибки несовместимым образом). Чтобы лучше понять явления, полезно проследить и понять отношения между ними.\n",
        "\n",
        "И то, и другое можно рассматривать как оценки максимального правдоподобия, просто с различными предположениями о зависимой переменной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCft2s4QpUs3"
      },
      "source": [
        "##  Функции активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y4-EiGWpUs3"
      },
      "source": [
        "Минимальным функциональным элементом нейронной сети является одиночный нейрон. Нейрон осуществляет две операции:\n",
        "1. вычисляет взвешенную смещенную суму значений его входов\n",
        "$$ z=\\sum_{i=1}^n w_i \\cdot x_i+b=WX+b,$$\n",
        "где $W$ обозначает вектор весов, $X$ обозначает вектор входных значений, а $b$ задаёт величину смещения.\n",
        "1. применяет к получившейся величине некоторую нелинейную функцию, называемую функцией активации\n",
        "$$ z \\rightarrow \\text{activation} (z)$$\n",
        "\n",
        "\n",
        "Взвешенная смещенная сумма входов $z$ может принимать значение на вещественной прямой. Данное значение  передается в функцию активации, которая, как правило, обладает другим множеством возможных значений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOYK9kClpUs3"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/neurons_output.png\"  width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "627z6lbZpUs3"
      },
      "source": [
        "Идея применения функций активации в структуре искусственных нейронных сетей обусловлена биологической аналогией. Известно, что в биологических нейронных сетях имеется аналог нелинейной функции активации: существует пороговый потенциал, только после достижения которого происходит возбуждение потенциала действие в клетке и, как следствие, распространение сигнала по нейронной сети. \n",
        "\n",
        "\n",
        "Именно таким простейшим образом ведёт себя пороговая функция активации, которая использовалась при построении первых искусственных нейронных сетей -- перцептронов:\n",
        "\n",
        "\n",
        "$f(x) =\n",
        "\\begin{cases}\n",
        "0, &\\text{$x<b$} \\\\ \n",
        "1, &\\text{$x\\geq b$}\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/threshold_function_plot.png\"  width=\"300\">\n",
        "\n",
        "\n",
        "Построенная с пороговой функцией активации нейронная сеть обладает ключевым недостатком, не позволяющим фактически использовать данную функцию активации на практике. В силу того что производная функции активации тривиальна прочти всюду на числовой прямой: \n",
        "\n",
        "$f'(x) =\n",
        "\\begin{cases}\n",
        "0, &\\text{$x\\neq b$} \\\\ \n",
        "?, &\\text{$x= b$}\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "не представляется возможным использовать метод градиентного спуска для оптимизации параметров нейронной сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTdAdrSPpUs4"
      },
      "source": [
        "###  Свойства функций активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APeNaCl_pUs4"
      },
      "source": [
        "Функции активации должны обладать следующими свойствами:\n",
        "\n",
        "* **Нелинейность:**\n",
        "Функция активации необходима для введения нелинейности в нейронные сети. Если функция активации не применяется, выходной сигнал становится простой линейной функцией. Неактивированная нейронная сеть будет действовать как линейная регрессия с ограниченной способностью к обучению:\n",
        "$$\\hat{y}=NN(X,W_1,...,W_n)=X\\cdot W_1\\cdot ...\\cdot W_n=X\\cdot W$$ \n",
        "Только нелинейные функции активации позволяют нейронным сетям решать задачи аппроксимации нелинейных функций:\n",
        "$$\\hat{y}=NN(X,W_1,...,W_n)=\\sigma(...\\sigma(X\\cdot W_1)...\\cdot W_n)\\neq X\\cdot W$$\n",
        "\n",
        "* **Возможность прохождения градиента:** \n",
        "Функции активации должны быть способными пропускать градиент, чтобы было возможно оптимизировать параметры сети градиентными методами, в частности использовать алгоритм обратного распространения ошибки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzMx_uzvpUs4"
      },
      "source": [
        "###  Различные функции активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzbXXrqXpUs4"
      },
      "source": [
        "Рассмотрим наиболее популярные функции активации и обсудим их преимущества и недостатки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNk7BfsjpUs4"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L05/popular_activation_functions.png\"  width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_GEAkqWpUs4"
      },
      "source": [
        "[AI in Pursuit of Happiness, Finding\n",
        "Only Sadness: Multi-Modal Facial\n",
        "Emotion Recognition Challenge  ](https://arxiv.org/pdf/1911.05187.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk-Bhe0ZpUs4"
      },
      "source": [
        "####  **Логистическая (сигмоидальная)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzAdTBkcpUs4"
      },
      "source": [
        "Sigmoid (сигмоидальная) для одномерного случая - используется в задачах классификации, в основном после выхода последнего нейрона. Позволяет определить вероятность принадлежности к одному из двух классов (0 или 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rMoJbAcpUs4"
      },
      "source": [
        "$$f(x)=\\frac{1}{1+e^{-x}}=\\frac{e^{x}}{e^{x}+1}=\\frac{1}{2}+\\frac{1}{2}tanh(\\frac{x}{2})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVyHlsAFpUs4"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_sigmoid.png\"  width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd3027xqpUs4"
      },
      "source": [
        "Производная логистической функции:\n",
        "\n",
        "$$\\frac{d}{dx}f(x)=\\frac{e^x\\cdot (1+e^x)-e^x \\cdot e^x}{(1+e^x)^2}=\\frac{e^x}{(1+e^x)^2}=f(x)(1-f(x))=f(x)f(-x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq7YVABXpUs4"
      },
      "source": [
        "Если активационная функция не бинарная (не как пороговая), то для нейрона возможны значения “активирован на 50%”, “активирован на 20%” и так далее. Если активированы несколько нейронов, можно найти нейрон с наибольшим значением активационной функции.\n",
        "\n",
        "Так как существуют промежуточные значения на выходе нейрона, **процесс обучения проходит более гладко и быстро**, а вероятность появления нескольких полностью активированных нейронов во время тренировки снижается по сравнению со ступенчатой функцией активации (хотя это зависит от того, что вы обучаете и на каких данных)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUSThMzgpUs4"
      },
      "source": [
        "```python\n",
        "torch.nn.Sigmoid()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_s_sVrgpUs4"
      },
      "outputs": [],
      "source": [
        "activation = nn.Sigmoid()\n",
        "input_values = torch.randn(5) * 5\n",
        "activation_sig = activation(input_values)\n",
        "print(f'input_values: {input_values}\\nactivation_sig: {activation_sig}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LXJ6G9hpUs4"
      },
      "source": [
        "Сигмоида выглядит гладкой и подобна пороговой функции.\n",
        "\n",
        "**Достоинства:**\n",
        "\n",
        "Во-первых, сигмоида — нелинейна по своей природе, а комбинация таких функций производит тоже нелинейную функцию. Поэтому мы можем конструировать многослойные сети.\n",
        "\n",
        "Еще одно достоинство такой функции — она гладкая, следовательно, улучшается гладкость градиента, в отличие от ступенчатой функции."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaMg6U1SpUs4"
      },
      "source": [
        "\n",
        "**Недостатки:**\n",
        "\n",
        "Насыщение сигмоиды приводит к затуханию градиентов. Крайне нежелательное свойство сигмоиды заключается в том, что при насыщении функции с той или иной стороны (0 или 1), градиент на этих участках становится близок к нулю. Напомним, что в процессе обратного распространения ошибки данный (локальный) градиент умножается на общий градиент. Следовательно, если локальный градиент очень мал, он фактически обнуляет общий градиент. В результате, сигнал почти не будет проходить через нейрон к его весам и рекурсивно к его данным. Кроме того, следует быть очень осторожным при инициализации весов сигмоидных нейронов, чтобы предотвратить насыщение. Например, если исходные веса имеют слишком большие значения, большинство нейронов перейдет в состояние насыщения, в результате чего сеть будет плохо обучаться."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP8qe47jpUs5"
      },
      "source": [
        "Выход сигмоиды не центрирован относительно нуля. Это свойство является нежелательным, поскольку нейроны в последующих слоях будут получать значения, которые не центрированы относительно нуля, что оказывает влияние на динамику градиентного спуска. Если значения, поступающие в нейрон, всегда положительны (например, $x > 0$ поэлементно в $f = wx + b$), тогда в процессе обратного распространения ошибки все градиенты весов $w$ будут либо положительны, либо отрицательны (в зависимости от градиента всего выражения $f$). Это может привести к нежелательной зигзагообразной динамике обновлений весов. Однако следует отметить, что когда эти градиенты суммируются по пакету, итоговое обновление весов может иметь различные знаки, что отчасти нивелирует описанный недостаток. Таким образом, отсутствие центрирования является неудобством, но имеет менее серьезные последствия, по сравнению с проблемой насыщения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwfmweOKpUs5"
      },
      "source": [
        "####  **Гиперболический тангенс**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62P5AFDpUs5"
      },
      "source": [
        "Гиперболический тангенс по определению близок к логистической функции. Данные функции можно выразить друг через друга просто через масштабное преобразование:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxpLJH8FpUs5"
      },
      "source": [
        "$$f(x)=tanh(x)=\\frac{2}{1+e^{-2x}}-1$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UXhz7i7pUs5"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_tanh.png\"  width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nx1l02QpUs5"
      },
      "source": [
        "Гиперболический тангенс симметричен относительно нуля и может принимать как положительные, так и отрицательные значения. Данное свойство гиперболического тангенса оказывается важным, в частности, при построении рекуррентных нейронных сетей. При использовании в рекуррентных сетях, получаемые на выходе $\\tanh (x)$ положительные или отрицательные значения могут не только увеличивать величину скрытого состояния в ячейках памяти, но и уменьшать их.\n",
        "\n",
        "**Достоинства**: В силу близкого определения, гиперболический тангенс обладает основными достоинствами описанной выше логистической функции. Кроме того, множество значений данной функции активации симметрично относительно нуля ($[-1,1]$). Использование гиперболического косинуса в качестве функции активации хорошо подходит для последовательного соединения полносвязных слоёв нейронной сети.\n",
        "\n",
        "**Недостатки**: Производная гиперболического косинуса аналогична по структуре производной логистической функции, следовательно при использовании гиперболического косинуса в качестве функции активации мы также можем столкнуться с проблемой затухания градиентов в области насыщения функции.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWpNJ3ARpUs5"
      },
      "source": [
        "```python\n",
        "torch.nn.Tanh()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLhcHovBpUs5"
      },
      "outputs": [],
      "source": [
        "activation = nn.Tanh()\n",
        "input_values = torch.tensor([11.1529,  4.3029,  0.5081, -3.8456, -1.9058])\n",
        "activation_tanh = activation(input_values)\n",
        "print(f'input_values: {input_values}\\nactivation_tanh: {activation_tanh}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnAa3YFppUs5"
      },
      "source": [
        "####  **ReLU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B1ajUc2pUs5"
      },
      "source": [
        "Часто на практике часто применяется функция активации ReLU. Значение данной функции равно нулю для всех отрицательных входных значений или совпадает с входным значением, если оно неотрицательно. Называние ReLU (rectified linear unit), \"выпрямитель\", связана с электротехнической аналогией -- график вольт-амерной характеристики идеального выпрямительного диода похож на график функции ReLU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KdZwqpYpUs5"
      },
      "source": [
        "$$relu(x)=max(0,x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-M-MbvdpUs5"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_relu.png\"  width=\"550\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GD3qjRapUs5"
      },
      "source": [
        "Производная ReLU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYl7I6m6pUs5"
      },
      "source": [
        "$$\\frac{d}{dx}relu(x) =\n",
        "\\begin{cases}\n",
        "\\frac{d}{dx}0, &\\text{$x<0$} \\\\ \n",
        "\\frac{d}{dx}x, &\\text{$x\\geq0$}\n",
        "\\end{cases}=\n",
        "\\begin{cases}\n",
        "0, &\\text{$x<0$} \\\\ \n",
        "1, &\\text{$x\\geq0$}\n",
        "\\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIuphkh2pUs5"
      },
      "source": [
        "```python\n",
        "torch.nn.ReLU()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejKT6C4xpUs5"
      },
      "outputs": [],
      "source": [
        "activation = nn.ReLU()\n",
        "input_values = torch.randn(5)\n",
        "activation_relu = activation(input_values)\n",
        "print(f'input_values: {input_values}\\nactivation_relu: {activation_relu}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdVxTA0TpUs5"
      },
      "source": [
        "Рассмотрим положительные и отрицательные стороны ReLU.\n",
        "\n",
        "**Достоинства:** \n",
        "\n",
        "Функция Relu не требует проведения вычислений в вещественной арифметике, как того требую сигмоидальная функция или гиперболический тангенс. Кроме того, производной функции ReLU является просто кусочно-постоянная функция и также может быть вычислена крайне эффективно. Это приводит к тому, что количество необходимых вычислительных ресурсов для обучения нейронной сети с использованием RuLu активаций оказывается значительно ниже, нежели чем при использовании рассмотренных выше логистической функции или $\\text{tanh} (x)$. Необходимо также отметить, что использование ReLu не приводит к эффекту насыщения градиента."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOX3HNH-pUs6"
      },
      "source": [
        "\n",
        "**Недостатки:**\n",
        "\n",
        "Иногда при использовании ReLU в качестве функции активации мы можем столкнуться с нежелательным эффектом отключения (\"умирания\") отдельных нейронов. Механизм данного явления связан с возможностью получения на выходе функции активации нулевого значения при широком диапазоне входных сигналов -- любая отрицательная линейная комбинация входных значений с весами нейрона будет преобразованная ReLU в ноль. Если при текущем обновлении весов нейрона изменение может оказаться слишком большим (например, при выборе слишком высокой скорости обучения), новая конфигурация весов нейрона будет при любых входных значениях приводить к отрицательной линейной комбинации и, как следствие, тожественно равной нулю активации рассматриваемого нейрона. Такой нейрон также тождественно обратит в ноль и проходящий через него локальный градиент при обучении сети методом обратного распространения ошибки, что сделает практически невозможным возвращение нейрона в \"рабочее\" состояние. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D11FA_2FpUs6"
      },
      "source": [
        "#### **Leaky ReLU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsGcBuSFpUs6"
      },
      "source": [
        "Leaky ReLU (ReLU с «утечкой», название также обусловлено электротехнической аналогией) является простейшей модификацией описанной выше ReLU, призванной исправить проблему \"умирания\" отдельных нейронов. В отличие от ReLU данная функция не равна константе $0$ при всех отрицательных входных значениях, а реализует в этой области линейную зависимость с небольшим угловым коэффициентом (например, с угловым коэффициентом $10^{-2}$). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMd4kTMbpUs6"
      },
      "source": [
        "$$lrelu(x)=max(0.01x,x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3ilne4IpUs6"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_leaky_relu.png\"  width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArjAsq17pUs6"
      },
      "source": [
        "Производная leaky ReLU:\n",
        "\n",
        "$$\\frac{d}{dx}lrelu(x)=\\frac{d}{dx}max(0.01x,x)=\\begin{cases}\n",
        "\\frac{d}{dx}0.01x, &\\text{$x<0$} \\\\ \n",
        "\\frac{d}{dx}x, &\\text{$x\\geq0$}\n",
        "\\end{cases}=\n",
        "\\begin{cases}\n",
        "0.01, &\\text{$x<0$} \\\\ \n",
        "1, &\\text{$x\\geq0$}\n",
        "\\end{cases}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuNr61mPpUs6"
      },
      "source": [
        "```python\n",
        "torch.nn.LeakyReLU()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUFDRixtpUs6"
      },
      "outputs": [],
      "source": [
        "activation = nn.LeakyReLU(0.01)\n",
        "input_values = torch.randn(5)\n",
        "activation_lrelu = activation(input_values)\n",
        "print(f'input_values: {input_values}\\nactivation_lrelu: {activation_lrelu}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB6kxIwFpUs6"
      },
      "source": [
        "**Достоинства**: Сохраняет достоинства ReLU, при этом не страдает от проблемы \"умирания\" \n",
        "\n",
        "**Недостатки**: Некоторые исследователи сообщают об успешном применении данной функции активации, но результаты не всегда стабильны."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3q5cbQipUs6"
      },
      "source": [
        "####  **GELU (Gaussian Error Linear Unit)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I923wgtcpUs6"
      },
      "source": [
        "Функция активации, используемая в трансформерах: Google BERT и OpenAI GPT-2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaMarSHdpUs6"
      },
      "source": [
        "$$GELU(x)=xP(X\\leq x)=x\\Phi(x)=x\\cdot \\frac{1}{2}[1+erf(\\frac{x}{\\sqrt{2}})]$$\n",
        "$$erf(x)=\\frac{2}{\\sqrt{\\pi}}\\int_0^xe^{-t^2}dt$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cJKqR0ApUs6"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_gelu.png\"  width=\"550\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcNK4RpopUs6"
      },
      "source": [
        "**Достоинства**: State-of-the-art функция активации в задачах NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBc6u1mkpUs6"
      },
      "outputs": [],
      "source": [
        "activation = nn.GELU()\n",
        "input_values = torch.randn(5) * 5\n",
        "activation_gelu = activation(input_values)\n",
        "print(f'input_values: {input_values}\\nactivation_gelu: {activation_gelu}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmf6Qk_0pUs6"
      },
      "source": [
        "### Визуализация функций активации:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrcQ2W3rpUs7"
      },
      "source": [
        "\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/animated_activation_functions.gif\"  width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfVTjMblpUs7"
      },
      "source": [
        "[Activation Functions Explained](https://mlfromscratch.com/activation-functions-explained/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYuzmNiTpUs7"
      },
      "source": [
        "#  2. Пример простой сети на датасете mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUwBZmCTpUs7"
      },
      "source": [
        "Загрузим датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfuhFCMOpUs7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from IPython.display import clear_output\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "train_set = MNIST(root='./MNIST', train=True, download=True, transform=transform)\n",
        "test_set = MNIST(root='./MNIST', train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhvjh9hNpUs7"
      },
      "source": [
        "Набор данных MNIST (англ. Modified National Institute of Standards and Technology) представляет собой модельный набор данных с изображениями рукописных цифр, который часто используется для обучения и оценки качества работы ML моделей классификации изображений.\n",
        "\n",
        "Датасет состоит из $60000$ тренировочных и $10000$ тестовых изображений. Все изображения имеют одинаковый квадратный размер $28 \\times 28$ пикселей и единственный цветовой канал. Рукописные изображения цифр имеют равный размер и располагаются в центре кадра. Кроме того, все изображения имеют одинаковую яркость. Всего датасет содержит 10 классов изображений -- цифры от $0$ до $9$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13YfTcJopUs7"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x_train = train_set.data.numpy() # images\n",
        "y_train = train_set.targets.numpy() # labels\n",
        "labels_names = list(map(str, range(10)))\n",
        "plt.figure(figsize = (20.0, 20.0))  \n",
        "for i in range(10):  # for all classes (0 to 9)\n",
        "  label_indexes = np.where(y_train == i)[0] # get indexes for each class \n",
        "  index = np.random.choice(label_indexes)\n",
        "  img = x_train[index]\n",
        "\n",
        "  plt.subplot(1, 10, i + 1)  \n",
        "  plt.title(labels_names[i])  \n",
        "  plt.axis(\"off\")  \n",
        "  imshow(img,cmap='gray')  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P-XC12FpUs7"
      },
      "source": [
        "В PyTorch для создания нейронных сетей требуется отнаследоваться от класса nn.Module и переопределить метод forward, в который подаются входные данные, и ожидаются выходные данные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtMs79PspUs7"
      },
      "source": [
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NoFoFOMpUs7"
      },
      "source": [
        "В класс мы добавляем две переменные, два слоя Linear. Linear -это слой, позволяющий, умножить веса на входной вектор и добавить смещение. Первый параметр - размер входного вектора, второй - размер выходного.\n",
        "\n",
        "В методе forward мы указываем последовательность применения операций для получения результата. Сначала изменим представление входного вектора, чтобы от изменения batch_size у нас ничего не сломалось.\n",
        "\n",
        "Далее идёт первый слой, после него функция активации relu и второй слой, возвращающий вектор длиной 10, означающий принадлежность к одному из классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d5b8bmTpUs7"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128) \n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x): # Called inside __call__ method\n",
        "        x = x.view(-1, 28*28) # \"reshape\" image to vector\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BYAIjg6pUs7"
      },
      "source": [
        "Наследование от nn.Module позволяет обращаться к параметрам сети через model.parameters(), а так же упростить много других вещей. **Это критически удобно для обучения сетей**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T96rQPr9pUs7"
      },
      "source": [
        "Второй вариант последовательного выполнения слоёв сети - [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) - объединение слоёв, вход одного слоя попадает в следующий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDQTusXTpUs7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "                                     nn.Linear(28*28, 128),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(128, 10)\n",
        "                                    )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxIU4QdHpUs7"
      },
      "outputs": [],
      "source": [
        "model = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPOVEHghpUs7"
      },
      "source": [
        "Определим нашу лосс-функцию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1aOlKS4pUs8"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayAky31ZpUs8"
      },
      "source": [
        "Определим оптимайзер для нашей сети. Оптимайзер, в библиотеках для нейронных сетей - это сущность, осуществляющая градиентный спуск. Подробнее об оптимайзере будет рассказано в дальнейших лекциях."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubOeBqjCpUs8"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVyoPt1opUs8"
      },
      "source": [
        "Обучим сеть десять эпох"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wdMReCipUs8"
      },
      "outputs": [],
      "source": [
        "from tqdm import trange\n",
        "\n",
        "num_epochs = 10\n",
        "loss_hist = [] # for plotting\n",
        "epochs = trange(num_epochs)\n",
        "for epoch in epochs:\n",
        "    hist_loss = 0\n",
        "    for _, batch in enumerate(train_loader, 0): # get batch\n",
        "        # обрабатываем batch \n",
        "        imgs, labels = batch\n",
        "        # Зануляем градиенты\n",
        "        optimizer.zero_grad() \n",
        "        # получаем выходы сети\n",
        "        pred = model(imgs) \n",
        "        # вычисляем loss\n",
        "        loss = criterion(pred, labels)\n",
        "        # вычисляем градиенты\n",
        "        loss.backward() \n",
        "        # выполняем один шаг оптимизатора (обновляем параметры сети)\n",
        "        optimizer.step()\n",
        "        hist_loss += loss.item()\n",
        "    loss_hist.append(hist_loss / len(train_loader))\n",
        "    epochs.set_description(f\"Epoch={epoch}  loss={loss_hist[epoch]:.4}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDE9HIk5pUs8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10, 5))\n",
        "plt.plot(range(num_epochs), loss_hist)\n",
        "plt.xlabel(\"Epochs\", fontsize=15)\n",
        "plt.ylabel(\"Loss\", fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXXe8B3MpUs8"
      },
      "source": [
        "Давайте посчитаем accuracy.\n",
        "\n",
        "Помните, что accuracy является частным случаем метрики качества, поэтому она не реализована в pytorch и поэтому с ней нужно быть аккуратней."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltTh8MLEpUs8"
      },
      "outputs": [],
      "source": [
        "def calaculate_accuracy(model, data_loader):\n",
        "    correct, total = 0, 0 \n",
        "    with torch.no_grad(): \n",
        "        for batch in data_loader: # get batch\n",
        "            imgs, labels = batch # parse batch\n",
        "            pred = model(imgs) # get output\n",
        "            _, predicted = torch.max(pred.data, 1) # get predicted class\n",
        "            total += labels.size(0) # all examples\n",
        "            correct += (predicted == labels).sum().item() # correct predictions \n",
        "    return correct / total "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF5dWOQPpUs8"
      },
      "outputs": [],
      "source": [
        "acc_train = round(calaculate_accuracy(model, train_loader), 2)\n",
        "print(f\"Accuracy train = {acc_train}\")\n",
        "acc_test = calaculate_accuracy(model, test_loader)\n",
        "print(f\"Accuracy test = {acc_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1!**  Дополните архитектуру нейросети. Постройте модель нейронной сети состоящую из трех полносвязных слоев, два из которых размера 128 с функцией активации ReLU, третий 10. В качестве ответа принимается значение **Accuracy test**.\n"
      ],
      "metadata": {
        "id": "ylRzqt59WzRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net_Big(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "                                    #код нужно вставить тут по аналогии с примером выше\n",
        "                                    #\n",
        "                                    #\n",
        "                                    #\n",
        "                                     \n",
        "                                    )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "model = Net_Big()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "loss_hist = [] # for plotting\n",
        "epochs = trange(num_epochs)\n",
        "for epoch in epochs:\n",
        "    hist_loss = 0\n",
        "    for _, batch in enumerate(train_loader, 0): # get batch\n",
        "        # обрабатываем batch \n",
        "        imgs, labels = batch\n",
        "        # Зануляем градиенты\n",
        "        optimizer.zero_grad() \n",
        "        # получаем выходы сети\n",
        "        pred = model(imgs) \n",
        "        # вычисляем loss\n",
        "        loss = criterion(pred, labels)\n",
        "        # вычисляем градиенты\n",
        "        loss.backward() \n",
        "        # выполняем один шаг оптимизатора (обновляем параметры сети)\n",
        "        optimizer.step()\n",
        "        hist_loss += loss.item()\n",
        "    loss_hist.append(hist_loss / len(train_loader))\n",
        "    epochs.set_description(f\"Epoch={epoch}  loss={loss_hist[epoch]:.4}\")\n",
        "\n",
        "acc_train = round(calaculate_accuracy(model, train_loader), 2)\n",
        "print(f\"Accuracy train = {acc_train}\")\n",
        "acc_test = calaculate_accuracy(model, test_loader)\n",
        "print(f\"Accuracy test = {acc_test}\")"
      ],
      "metadata": {
        "id": "p5uSgU4EXQpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, точность не улучшилась на тестовом наборе данных, скорее всего из-за слишком большого количества параметров наша сеть переобучилась."
      ],
      "metadata": {
        "id": "hpb9zi7tfTZz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFgRc45ipUs8"
      },
      "source": [
        "Поэтапно пропустим тестовые изображения через модель и визуализируем результат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fs7PoeBpUs8"
      },
      "outputs": [],
      "source": [
        "# get batch\n",
        "imgs, labels = next(iter(test_loader))\n",
        "print('imgs shape: ', imgs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sh-YnwPpUs8"
      },
      "outputs": [],
      "source": [
        "# get output\n",
        "pred = model(imgs)\n",
        "print('pred shape: ', pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgg500hvpUs8"
      },
      "outputs": [],
      "source": [
        "# First sample in prediction batch\n",
        "pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hmhj0Ie4pUs8"
      },
      "outputs": [],
      "source": [
        "# Calculate probabilities\n",
        "nn.Softmax(dim=0)(pred[0].detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3Leu8AbpUs8"
      },
      "outputs": [],
      "source": [
        "# remove axis\n",
        "imgs = torch.reshape(imgs, (64, 28, 28))\n",
        "print('imgs shape(after reshape): ', imgs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOO_-6aYpUs8"
      },
      "outputs": [],
      "source": [
        "# take 10 first images\n",
        "imgs = imgs[:10]\n",
        "print('imgs shape: ', imgs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXXcgsoSpUs8"
      },
      "outputs": [],
      "source": [
        "pred = pred[:10].detach()\n",
        "print('Prediction(1 sample):\\n', pred[0])\n",
        "digits = np.argmax(pred.numpy(), axis=1)\n",
        "print('Predicted class: ', digits[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTrC1MxtpUs9"
      },
      "source": [
        "Визуализируем изображения, подпишем предсказанное и истинное значение:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMSWi72CpUs9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (25.0, 25.0))\n",
        "for i in range(10):\n",
        "  img = imgs[i]\n",
        "\n",
        "  plt.subplot(1, 10, i + 1)\n",
        "  plt.title('pred: ' + str(digits[i]) + ' real: '+str(labels[i].numpy())) # predicted and real values\n",
        "  plt.axis(\"off\")\n",
        "  imshow(img.numpy(),cmap='gray') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGoZTNDupUs9"
      },
      "source": [
        "\n",
        " <font size=\"6\">Ссылки:</font>\n",
        "\n",
        "[StatSoft. Радиальная базисная функция](http://statsoft.ru/home/textbook/modules/stneunet.html#radial)\n",
        "\n",
        "[Важность функции потери в машинном обучении](https://towardsdatascience.com/importance-of-loss-function-in-machine-learning-eddaaec69519#:~:text=At%20its%20core%2C%20a%20loss,to%20minimize%20the%20loss%20function.)\n",
        "\n",
        "[Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names](https://gombru.github.io/2018/05/23/cross_entropy_loss/)\n",
        "\n",
        "[Функции активации нейросети: сигмоида, линейная, ступенчатая, ReLu, tahn](https://neurohive.io/ru/osnovy-data-science/activation-functions/)\n",
        "\n",
        "[Объясненные современные функции активации: GELU, SELU, ELU, ReLU и другие](https://mlfromscratch.com/activation-functions-explained/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iftK0X-HqPcz"
      },
      "source": [
        "# 3. Введение в сверточные нейронные сети\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psBeTR9FqPc0"
      },
      "source": [
        "## Полносвязная нейронная сеть \n",
        "Fully-connected Neural Network (FCN). В современных статьях чаще используется термин Multilayer Perceptron (MLP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Z4wipaqPc0"
      },
      "source": [
        "Мы рассмотрели следующий подход для классификации изображений:\n",
        "\n",
        "1. Превращаем исходные данные в вектор. \n",
        "\n",
        ">***Примечание***: при обработке цветного изображения размером $32\\times32$ пикселя ($32\\times32\\times3$), размерность входного вектора будет равна $3072$. Однако, в общем случае, модель получает на вход набор одноразмерных векторов (матрицу), потому при обработке одного изображения размер матрицы будет $3072\\times1$.\n",
        "\n",
        "2. Перемножаем матрицу данных с матрицей весов. Размер последней может быть, например, $100\\times3072$. Где $3072$ - размер входного вектора, а $100$ - количество признаков, которое мы хотим получить. Результат обработки одного изображения будет иметь размер $100\\times1$.\n",
        "\n",
        "3. Поэлементно применяем к полученной матрице нелинейную функцию (функцию активации), например Sigmoid или ReLU. Размерность данных при этом не меняется ($100\\times1$). В результате получаем вектор активаций или признаков.\n",
        "\n",
        "4. Используем полученные признаки как входные данные для нового слоя. Количество весов слоя будет зависеть от размерности входной матрицы и того, что мы хотим получить на выходе. Если мы делаем классификатор на $10$ классов, то матрица весов должна иметь размерность $10\\times100$, и на этом можно остановиться. Но в общем случае количество слоев может быть произвольным.\n",
        "\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/fully_connected_neural_network.png\" width=\"600\">\n",
        "\n",
        "\n",
        "На изображении представлена описанная выше нейронная сеть, функцией активации в которой является ReLU. Добавление второго слоя позволило модели использовать более одного шаблона на класс. Можно убедиться в этом, обучив модель на датасете CIFAR-10 и визуализировав веса первого слоя модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW_ujzOJqPc1"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/mlp_templates.jpg\" width=\"700\">\n",
        "\n",
        "За счёт создания нескольких шаблонов для каждого из классов, многослойные архитектуры в общем случае показывают более высокую, чем перцептроны, эффективность на задачах классификации изображений. Однако подход с использованием многослойного перцептрона также имеет свои недостатки. Чтобы обнаружить их, присмотримся к происходящему с данными при предобработке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m95WwvIwqPc2"
      },
      "source": [
        "## Нарушение связей между соседними пикселями\n",
        "\n",
        "Единственным этапом предобработки данных при использовании многослойного перцептрона является превращение изображения в вектор. Основной его проблемой является \"потеря связи\" между соседними пикселями, что показано на изображении ниже. В общем случае, значения из соседних пикселей могут оказаться на большом расстоянии внутри результирующего вектора. \n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/img_to_vector_problem.png\" width=\"600\">\n",
        "\n",
        "Словом, после преобразования, мы теряем информацию о взаимном расположении значений на исходном изображении - при подборе весов никак не используется информация о том, что какие-то значения были \\\"близки\\\" друг к другу на исходном изображении. При этом мы, люди, понимаем важность взаимосвязей между пикселями\n",
        "\n",
        "К примеру, набор тёмных пикселей находящихся поблизости внутри изображения может сообщить нам, что там располагается некий тёмный объект. Если же мы преобразуем изображение в вектор и эти значения \"разбросает\" по нему без сохранения пространственной структуры, то новому наблюдателю будет очень сложно понять, что где-то на исходном изображении была тёмная зона.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfDLQws2qPc2"
      },
      "source": [
        "Идея полносвязной нейронной сети пришла к нам из математической модели восприятия информации мозгом ([перцептрон Розенблатта](http://www.machinelearning.ru/wiki/index.php?title=%D0%9F%D0%B5%D1%80%D1%81%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD)). Возможно, чтобы получить хорошие результаты при обработке изображений, нужно посмотреть, как работает человеческий глаз? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvndhXmAqPc3"
      },
      "source": [
        "### Рецептивное поле\n",
        "Когда мы смотрим на объект, мы видим свет, который:\n",
        "- отражается от объекта, \n",
        "- проходит сложную оптическую систему для настройки яркости и фокусировки (нам это не интересно, т.к. эту задачу по большей части решает настройка фотоаппарата),\n",
        "- попадает на сетчатку, которая преобразует этот свет в нервные импульсы, которые передаются мозгу по зрительному тракту (звучит, как то, что нам надо)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVgy0ClOqPc4"
      },
      "source": [
        "Посмотрим, как работает сетчатка:\n",
        "1. Свет возбуждает фоторецепторы сетчатки (палочки и колбочки).\n",
        "2. Биполярные клетки собирают информацию с группы близко расположенных рецепторов, преобразуют ее и передают дальше. Каждая биполярная клетка возбуждается при определенной комбинации сигналов от связанных с ней рецепторных клеток. По сути она ищет некоторый не сложный, локально расположенный паттерн в изображении, попавшем на сетчатку. \n",
        "3. Клетки уровнем выше собирают информацию с нескольких близко расположенных биполярных клеток и активируются при уникальной комбинации сигналов с них.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/L06_perceptual_field_retina.png\" width=\"700\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq04uq4ZqPc4"
      },
      "source": [
        "В такой системе появляется понятие **рецептивного поля** нейрона. \n",
        "\n",
        "**Рецептивное поле** нейрона - это участок с рецепторами с которых он прямо или опосредованно, через другие нейроны, получает информацию. В случае глаза - рецептивное поле будет локализовано в некоторой области сетчатки глаза. При удалении от сетчатки рецептивное поле нерона будет увеличиваться в каждом следующем слое неронов: рецептивное поле ганглиозной клетки будет больше чем у биполярной. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLK-khPgqPc5"
      },
      "source": [
        "### Фильтрация изображений "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDh28TBJqPc5"
      },
      "source": [
        "Идея обработки изображения, путем преобразования пикселя с учетом значений соседних пикселей широко применяется в обработке изображений. Такое преобразование называют **фильтрацией**. Вы наверняка слышали о наложении фильтров на изображения, если работали в графических редакторах, например, в Photoshop. \n",
        "\n",
        "При фильтрации одно и то же преобразование применяется к каждому участку изображения. Это можно представить, как некоторый паттерн, который скользит по изображению и вычисляет итоговое значение. \n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_with_filter.gif\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly5wJimGqPc5"
      },
      "source": [
        "## Примеры 'hand-crafted' фильтров\n",
        "\n",
        "Для реализации идеи локальности при обработке данных используется операция свёртки. Свёртка требует тензор параметров - \\\"ядро свёртки\\\", также называемое фильтром. \n",
        "\n",
        "В течение долгого времени веса в фильтрах подбирались вручную. Этого было достаточно для простой обработки изображений. Например, к таким фильтрам можно отнести фильтр Гаусса, фильтр Собеля, детекторы углов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVI_PWfBqPc8"
      },
      "source": [
        "## Свертка с фильтром"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JyKkDfmqPc8"
      },
      "source": [
        "По сути своей, операция свёртки - это та же самая взвешенная сумма с добавлением свободного члена, используемая в полносвязных линейных слоях. \n",
        "\n",
        "Ключевое отличие между линейным слоем и свёрткой заключается в том, что линейный слой получает на вход всё изображение, тогда как свёртка - небольшие фрагменты изображения. То есть, если при обработке линейным слоем всё изображение сравнивалось с шаблонами, то теперь лишь небольшие фрагменты изображения сравниваются с шаблонами.\n",
        "\n",
        "К примеру, на GIF ниже можно увидеть, как фильтр размером $3\\times3$ применяется к одноканальному изображению размером $5\\times5$. Шаблон имеет форму x-образного креста. В правой части можно увидеть, насколько фрагмент изображения под фильтром совпадает с шаблоном внутри фильтра.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_with_filter.gif\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ei-gC0TqPc8"
      },
      "source": [
        "Реализуем это в коде:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaHDE4fqqPc8"
      },
      "outputs": [],
      "source": [
        "img = torch.Tensor([[1,1,1,0,0],\n",
        "                    [0,1,1,1,0],\n",
        "                    [0,0,1,1,1],\n",
        "                    [0,0,1,1,0],\n",
        "                    [0,1,1,0,0]])\n",
        "\n",
        "kernel = torch.Tensor([[1, 0, 1],\n",
        "                       [0, 1, 0],\n",
        "                       [1, 0, 1]])\n",
        "\n",
        "result = torch.zeros((3,3)) # img - kernel + 1 (5 - 3 + 1 = 3)\n",
        "\n",
        "for i in range(0, result.shape[0]):\n",
        "    for j in range(0, result.shape[1]):\n",
        "        segment = img[i:i+kernel.shape[0], \n",
        "                        j:j+kernel.shape[1]]\n",
        "        result[i, j] = torch.sum(segment * kernel)\n",
        "\n",
        "print(f'img shape: {img.shape}')\n",
        "print(f'kernel shape: {kernel.shape}')\n",
        "print(f'result shape: {result.shape}')\n",
        "print(f'result:\\n{result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcZJfqroqPc8"
      },
      "source": [
        "# 4. Сверточный слой нейросети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZF22TShqPc9"
      },
      "source": [
        "## Основные параметры свёртки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujWoa1idqPc9"
      },
      "source": [
        "Как уже упоминалось ранее, по сути, операция свёртки представляет из себя вычисление взвешенной суммы со свободным членом, что довольно сильно напоминает линейный слой с тем лишь отличием, что последний применяется ко всем данным, а не к их части. Тем не менее, подобно линейному слою, операцию свёртки можно встроить в нейросеть и, путём градиентного спуска, подбирать параметры свёртки. \n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/img_and_convolution_filter.png\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjYiF_NdqPc9"
      },
      "source": [
        "Реализуем операцию свертки с помощью линейного слоя:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdNIswMhqPc9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "local_linear = nn.Linear(9, 1, bias=False) # 9 = 3 * 3 (weights shape: (3,3))\n",
        "\n",
        "img = torch.Tensor([[1,1,1,0,0],\n",
        "                    [0,1,1,1,0],\n",
        "                    [0,0,1,1,1],\n",
        "                    [0,0,1,1,0],\n",
        "                    [0,1,1,0,0]])\n",
        "# kernel weights\n",
        "weights = torch.Tensor([[1, 0, 1],\n",
        "                       [0, 1, 0],\n",
        "                       [1, 0, 1]])\n",
        "\n",
        "local_linear.weight = nn.Parameter(weights.reshape(-1)) # set weights \n",
        "\n",
        "result = torch.zeros((3,3)) # img - kernel + 1 (5 - 3 + 1 = 3)\n",
        "\n",
        "for i in range(0, result.shape[0]):\n",
        "    for j in range(0, result.shape[1]):\n",
        "        segment = img[i:i+weights.shape[0], \n",
        "                        j:j+weights.shape[1]].reshape(-1)\n",
        "        result[i, j] = local_linear(segment)\n",
        "\n",
        "print(f'img shape: {img.shape}')\n",
        "print(f'weights shape: {weights.shape}')\n",
        "print(f'result shape: {result.shape}')\n",
        "print(f'result:\\n{result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYOhRSguqPc9"
      },
      "source": [
        "### Обработка цветных/многоканальных изображений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OlcMIUMqPc9"
      },
      "source": [
        "В примерах выше мы рассматривали [черно-белые](https://ru.wikipedia.org/wiki/%D0%A7%D1%91%D1%80%D0%BD%D0%BE-%D0%B1%D0%B5%D0%BB%D0%B0%D1%8F_%D1%84%D0%BE%D1%82%D0%BE%D0%B3%D1%80%D0%B0%D1%84%D0%B8%D1%8F) изображения. Их также называют одноканальными изображениями, т.к. в них цвет пикселя определяется одним числом, характеризующим яркость.\n",
        "\n",
        "Однако, на практике часто сталкиваются с трехканальными цветными [RGB](https://ru.wikipedia.org/wiki/RGB) изображениями, в которых цвет пикселя определяется тремя числами, характеризующими три основных цвета (красный, зеленый и синий). \n",
        "\n",
        "Анализируемое изображение может иметь и большее количество каналов. Например: марсоход Opportunity для получения изображений использовал [13 фильтров](https://habr.com/ru/post/160621/).  \n",
        "\n",
        "В общем случае, изображение имеет размер $C \\times H\\times W$. К примеру, изображения из датасета CIFAR-10 имеют размер $3\\times32\\times32$.  \n",
        "\n",
        "При обработке подобных изображений, используется уже не матрица, а трёхмерный тензор. Ниже демонстрируется процесс обработки фрагмента трёхмерного изображения фильтром размерности $3\\times3$:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/rgb_image_and_convolution_filter.png\" width=\"400\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvMAYXfCqPc9"
      },
      "source": [
        "Результатом свертки входного тензора с одним фильтром будет карта признаков с глубиной 1, вне зависимости от количества каналов входного тензора.\n",
        "\n",
        "Во время прямого прохода фильтр перемещается по ширине и высоте входного тензора и вычисляются скалярные произведения между значениями фильтра и соответствующими значениями входного тензора. Так формируется двумерная карта признаков, которая содержит результат применения данного фильтра к каждой из областей входного тензора.\n",
        "\n",
        "В качестве входного тензора можно использовать не изображение, а результат предыдущего сверточного слоя. \n",
        "\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_filter_forward_pass.png\" width=\"200\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mDbsyq5qPc9"
      },
      "outputs": [],
      "source": [
        "img = torch.randn((3, 8, 8)) # 3-num of channels, (8,8)-img size\n",
        "kernel = torch.randn((3, 3, 3)) # 3-num of filters, (3,3)-kernel size\n",
        "\n",
        "result = torch.zeros(6, 6) # 8 - 3 + 1 = 6\n",
        "\n",
        "for i in range(result.shape[0]):\n",
        "  for j in range(result.shape[1]):\n",
        "    segment = img[:, \n",
        "                    i:i+kernel.shape[0], \n",
        "                    j:j+kernel.shape[1]]\n",
        "    result[i, j] = torch.sum(segment * kernel)\n",
        "\n",
        "print(f'img shape: {img.shape}')\n",
        "print(f'kernel shape: {kernel.shape}')\n",
        "print(f'result shape: {result.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGG5xm7qPc-"
      },
      "source": [
        "### Использование нескольких фильтров\n",
        "\n",
        "Подобно тому, как в перцептроне использовались несколько выходных нейронов, чтобы передать информацию о сходстве входного вектора с различными шаблонами, можно использовать несколько фильтров при свёртке. То есть, выполнять свёртку несколько раз ($C_{out}$, по количеству фильтров)  с разными фильтрами. В результате появится несколько карт признаков, имеющих размер $1\\times H_{out}\\times W_{out}$. При объединении этих карт будет получен тензор размерности $C_{out}\\times H_{out} \\times W_{out}$, где $C_{out}$ - количество фильтров, а также количество \"каналов\" в полученном представлении. Полученное представление может быть без проблем передано для следующей операции свёртки. \n",
        "\n",
        "На изображении ниже продемонстрирован результат применения сверточного слоя, содержащего $5$ фильтров, к изображению из CIFAR-10. \n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_layer_with_5_filters.png\" width=\"400\"> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0XCDWNxqPc-"
      },
      "source": [
        "В свёрточном слое указаны параметры, необходимые для создания ядра свёртки - количество каналов во входном представлении `in_channels` и размер ядра свёртки `kernel_size`. Также в нём необходимо указывать количество используемых фильтров `out_channels`. Стоит отметить, что, в отличие от полносвязанного слоя, свёрточный слой не требует информации о количестве значений во входном представлении и может быть использован как для представлений $C_{in} \\times 32 \\times 32$, так и $C_{in} \\times 100 \\times 100$. Словом, представления могут иметь практически любой размер, главное чтобы пространственные размеры не были меньше размеров ядра свёртки.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BIU5u5-qPc-"
      },
      "outputs": [],
      "source": [
        "conv = torch.nn.Conv2d(in_channels=3,  # Количество входных каналов (3 для RGB изображений)\n",
        "                       out_channels=5, # Количество фильтров/выходных каналов\n",
        "                       kernel_size=3)\n",
        "\n",
        "img = torch.randn((1, 3, 100, 100)) # 1-размер батча, 3-количество каналов, (100,100)-размер изображения\n",
        "print(f'img shape: {img.shape}')\n",
        "\n",
        "out = conv(img)\n",
        "print(f'out shape: {out.shape}') # [1, 5, 98, 98]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roV2J2H_qPc-"
      },
      "source": [
        "### Уменьшение размера представлений\n",
        "\n",
        "Заметим, что при свёртке ширина $W_{out}$ и высота $H_{out}$ **карты признаков** будут отличаться от **пространственных размерностей** $W_{in}$ и $H_{in}$ исходного тензора. К примеру, при обработке трёхканального тензора размера $32 \\times 32$ ядром размера $5 \\times 5$, можно будет произвести лишь $27$ сдвигов $(32 - 5)$ по вертикали и столько же - по горизонтали. Но при этом размер итоговой карты признаков будет равен $28 \\times 28$, поскольку первый ряд (либо столбец) можно получить без сдвигов по вертикали либо горизонтали, соответственно. При повторном применении фильтра, размер каждой из сторон уменьшится ещё на $4$. Итоговое значение $N'$ пространственной размерности $N$ при размере стороны фильтра $F$ вычисляется по следующей формуле: $N' = N - F + 1$.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/decrease_size_of_image_after_convolution.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py7pfuAsqPc-"
      },
      "outputs": [],
      "source": [
        "conv_1 = torch.nn.Conv2d(in_channels=3, # Number of input channels (3 for RGB images)\n",
        "                       out_channels=6, # Number of filters/output channels\n",
        "                       kernel_size=5)\n",
        "\n",
        "conv_2 = torch.nn.Conv2d(in_channels=6, # Number of input channels (3 for RGB images)\n",
        "                              out_channels=10, # Number of filters/output channels\n",
        "                              kernel_size=5)\n",
        "\n",
        "img = torch.randn((1, 3, 32, 32)) # 1-batch size, 3-num of channels, (32,32)-img size\n",
        "print(f'img shape: {img.shape}')\n",
        "\n",
        "out_1 = conv_1(img)\n",
        "print(f'out_1 shape: {out_1.shape}') # [1, 6, 28, 28]\n",
        "\n",
        "out_2 = conv_2(out_1)\n",
        "print(f'out_2 shape: {out_2.shape}') # [1, 10, 24, 24]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "624rGMMYqPc-"
      },
      "source": [
        "Заметим, что при уменьшении размера представлений пиксели, находящиеся около краёв, участвуют в значительно меньшем количестве свёрток, чем пиксели в середине, хотя информация в них не обязательно менее ценна, чем информация из центральных пикселей. К примеру, пиксель в верхнем левом углу представления вне зависимости от размера фильтра будет принимать участие лишь в одной свёртке и информация о нём будет сохранена лишь в верхнем левом углу нового представления. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUb_hOS0qPc-"
      },
      "source": [
        "### Расширение (padding)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xv3UYm5qPc-"
      },
      "source": [
        "Для борьбы с описанной выше проблемой применяется *паддинг(дополнение)* входного тензора (англ. *padding*). В ходе него ширина и высота тензора увеличиваются за счёт приписывания столбцов и строк с некими значениями. К примеру, на изображении ниже перед свёрткой ядром размера $3\\times3$ был применён padding нулями размера 1.  \n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/padding.png\" width=\"250\">\n",
        "\n",
        "На примере убедимся, что это позволит нам сохранить пространственные размерности тензоров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8WA5r5iqPc_"
      },
      "outputs": [],
      "source": [
        "img = torch.randn((1, 1, 5, 5)) # create random image\n",
        "print(f'Original tensor:\\nshape:{img.shape}:\\n {img}')\n",
        "\n",
        "# add zeros to image manually\n",
        "padded_img = torch.zeros((1, 1, 7, 7)) # create zeros array to insert image in center\n",
        "padded_img[:, :, 1:-1, 1:-1] += img # insert image, we get image arounded by zeros\n",
        "print(f'\\nPadded tensor:\\nshape:{padded_img.shape}:\\n {padded_img}')\n",
        "\n",
        "# define two conv layers to check results\n",
        "conv_3 = torch.nn.Conv2d(in_channels=1, \n",
        "                        out_channels=1, \n",
        "                        kernel_size=3)\n",
        "conv_5 = torch.nn.Conv2d(in_channels=1, \n",
        "                        out_channels=1, \n",
        "                        kernel_size=5)\n",
        "# use layers separately, to compare results\n",
        "conved_3 = conv_3(img)\n",
        "conved_5 = conv_5(img)\n",
        "\n",
        "conved_pad_3 = conv_3(padded_img)\n",
        "conved_pad_5 = conv_5(padded_img)\n",
        "\n",
        "print('\\n\\nOriginal shape:', img.shape)\n",
        "print('Shape after convolution layer(kernel 3x3):', conved_3.shape)\n",
        "print('Shape after convolution layer(kernel 5x5):', conved_5.shape)\n",
        "\n",
        "print('\\n\\nPadded shape:', padded_img.shape)\n",
        "print('Shape after convolution with padding(kernel 3x3):', conved_pad_3.shape)\n",
        "print('Shape after convolution with padding(kernel 5x5):', conved_pad_5.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74Hi0dVlqPc_"
      },
      "source": [
        "Заметим, что дополнение одним рядом и одним столбцом не является универсальным решением: для фильтра размером 5 размер выходного тензора всё равно отличается от входного. Если мы немного видоизменим полученную выше формулу (используя размер дополнения $P$), то получим следующую формулу: $N' = N + 2\\cdot P - F + 1$.  \n",
        "Видно, для того чтобы пространственные размеры не изменялись ($N' = N$), для разных размеров фильтра требуются разные размеры паддинга. В общем случае, для размера фильтра $F$, требуемый размер дополнения  $\\displaystyle P = \\frac{F-1}{2}$. \n",
        "\n",
        "\n",
        "Важными терминами, связанными с паддингом, являются \"*same padding*\" - размер выходного тензора не отличается от размера входного тензора, а также \"*valid padding*\" - отсутствие паддинга.\n",
        "\n",
        "```\n",
        "\"VALID\" = без паддинга:\n",
        "\n",
        "   inputs:         1  2  3  4  5  6  7  8  9  10 11 (12 13)\n",
        "                  |________________|                dropped\n",
        "                                 |_________________|\n",
        "\"SAME\" = с паддингом нулями:\n",
        "\n",
        "               pad|                                      |pad\n",
        "   inputs:      0 |1  2  3  4  5  6  7  8  9  10 11 12 13|0  0\n",
        "               |________________|\n",
        "                              |_________________|\n",
        "                                             |________________|\n",
        "```\n",
        "\n",
        "Ниже можно увидеть пример обработки RGB изображения с same padding (с использованием 0):\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_with_same_padding_rgb_image.gif\" width=\"780\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbK7PZ_-qPc_"
      },
      "source": [
        "Теперь реализуем padding, используя инструментарий torch и сравним его с ручным добавлением padding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_b75ySFqPc_"
      },
      "outputs": [],
      "source": [
        "img = torch.randn((1, 1, 5, 5)) # define random image\n",
        "\n",
        "# add zeros manually\n",
        "padded_img = torch.zeros((1, 1, 7, 7)) \n",
        "padded_img[:, :, 1:-1, 1:-1] += img\n",
        "\n",
        "# conv layer without padding (padding=0 by default)\n",
        "conv_3 = torch.nn.Conv2d(in_channels=1, \n",
        "                        out_channels=1, \n",
        "                        kernel_size=3,\n",
        "                        padding=0)\n",
        "\n",
        "# conv layer with padding = 1 (add zeros)\n",
        "conv_3_padded = torch.nn.Conv2d(in_channels=1, \n",
        "                                out_channels=1, \n",
        "                                kernel_size=3,\n",
        "                                padding=1) # Padding added 1 zeros line to all four sides of the input\n",
        "original = conv_3(padded_img)\n",
        "padded = conv_3_padded(img)\n",
        "\n",
        "print(f'Explicitly padded:\\n {original.shape}\\n {original}')\n",
        "print(f'\\nImplicitly padded:\\n{padded.shape}\\n  {padded}')\n",
        "print(\"\\nExplicitly padded shape = Implicitly padded shape\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvBZcgJFqPc_"
      },
      "source": [
        "### Изменение разметров карт признаков, при прохождении через свёрточный слой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc0jD48oqPc_"
      },
      "source": [
        "Как мы успели рассмотреть выше, свёрточный слой нейросети осуществляет преобразование некоторого набора входных карт признаков в новый определенный набор выходных карт признаков. Выбор параметров ядра свёртки, числа входных и выходных каналов, величина и тип расширения (padding) полностью определяет \"геометрию\" данного преобразование.\n",
        "\n",
        "На практике, при написании собственных нейронных сетей со свёрточными слоями, мы хотим последовательно пропускать изображение через несколько свёрточных слоёв: передавая полученные на выходе одного свёрточного слоя карты признаков на вход другому. \n",
        "\n",
        "Как уже отмечалось выше, свёрточные слои могут принимать на вход карты признаков произвольной ширины и высоты (главное, чтобы ширина и высота карты признаков после расширения (padding) была не меньше размера ядра свёртки) — таким образом, при последовательном соединении свёрточных слоёв остаётся обеспечить согласование числа карт признаков: количество карт признаков на выходе слоя должно равняться числу входных карт признаков следующего после него.\n",
        "\n",
        "При построении некоторых архитектур CNN (например, для архитектуры [UNET](https://arxiv.org/abs/1505.04597)) важно явно контролировать пространственные размеры всех используемых карт признаков. Чтобы разобраться как происходит преобразование размеров карт признаков, обратимся к описанию класса [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d) из библиотеки PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-RmuvW8qPc_"
      },
      "source": [
        "`torch.nn.Conv2d` принимает на вход тензор вида $(N, C_{in}, H, W)$, где $N$ нулевом измерении (как всегда) соответствует размерности батча, $C_{in}$ соответствует числу входных карт признаков, а $H$ и $W$ задают пространственные размеры входных карт признаков. На выходе мы получаем тензор вида $(N, C_{out}, H_{out}, W_{out})$, где количество выходных карт признаков $C_{out}$ задаётся при создании экземпляра класса `torch.nn.Conv2d`, а пространственные измерения выходных карт признаков $H_{out}$ и $W_{out}$ вычисляются на основе параметров ядра свёртки и размеров $H$ и $W$ входных карт признаков по формулам:\n",
        "\n",
        "$$ H_{out} = \\lfloor \\frac{H + 2 \\times \\text{padding_h} - \\text{dilation_h} \\times (\\text{kernek_size_h} - 1) -1}{\\text{stride_h}}  + 1 \\rfloor ,$$\n",
        "$$ W_{out} = \\lfloor \\frac{W + 2 \\times \\text{padding_w} - \\text{dilation_w} \\times (\\text{kernek_size_w} - 1) -1}{\\text{stride_w}}  + 1 \\rfloor ,$$\n",
        "\n",
        "где\n",
        "* `kernek_size_h` и `kernek_size_w` -- количество элементов ядра свёртки по ширине и высоте\n",
        "* `padding_h` и `padding_w` --  параметры расширения выходной карты признаков нулями по ширине и высоте \n",
        "* `stride_h` и `stride_w` -- сдвиг свёртки по ширине и высоте, будет подробно рассмотрено ниже\n",
        "* `dilation_h` и `dilation_w` -- расстояние между ядерными элементами(позволяет рассматривать только те пространственные элементы карты признаков, координаты которых кратны величинам сдвига по ширине и высоте; по умолчанию данная величина равна $1$ и в свёртке принимает участие вся карта признаков); С dilated convolutions мы подробнее познакомимся при рассмотрении CNN архитектур, используемых для семантической сегментации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8r-bDdwqPc_"
      },
      "source": [
        "Интерактивный пример преобразования набора входных карт признаков свёрточным слоем:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp5MDp79qPc_"
      },
      "outputs": [],
      "source": [
        "#@title \\<code block for conv2d visualization purposes\\>\n",
        " \n",
        "from torch import Tensor\n",
        "\n",
        "from ipywidgets import interactive\n",
        "import ipywidgets as widgets\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def plot_featuremaps(\n",
        "    featuremap_tensor : Tensor,\n",
        "    title : str='',\n",
        "    v_max : int=None\n",
        ") -> None:\n",
        "    n_maps, h, w = featuremap_tensor.shape[1:]\n",
        "    fig, ax = plt.subplots(ncols=n_maps,\n",
        "                           figsize=(5*n_maps, 5),\n",
        "                           sharex=False,\n",
        "                           sharey=False)\n",
        "    \n",
        "    featuremap_tensor = featuremap_tensor.detach()\n",
        "    if n_maps > 1:\n",
        "      for id_ax in range(n_maps):\n",
        "          sns.heatmap(featuremap_tensor[0][id_ax], ax=ax[id_ax], annot=True, \n",
        "                      fmt=\"0.00f\", cbar=False, vmin=0, vmax=v_max, linewidths=1)\n",
        "    else:\n",
        "        sns.heatmap(featuremap_tensor[0][0], ax=ax, annot=True, \n",
        "                    fmt=\"0.00f\", cbar=False, vmin=0, vmax=v_max, linewidths=1)\n",
        "    \n",
        "    fig.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def conv2d_example(\n",
        "    h_in : int = 8,\n",
        "    w_in : int = 8,\n",
        "    in_channels : int = 2,\n",
        "    out_channels : int = 1,\n",
        "    kernel_size_h : int = 3,\n",
        "    kernel_size_w : int = 3,\n",
        "    padding_h : int = 0,\n",
        "    padding_w : int = 0,\n",
        "    stride_h : int = 1,\n",
        "    stride_w : int = 1,\n",
        "    dilation_h : int = 1,\n",
        "    dilation_w : int = 1,\n",
        ") -> None:\n",
        "    '''\n",
        "      This function generates an example of the input\n",
        "      feature maps tensor, passes it to a two-dimensional \n",
        "      convolution with the specified parameters and \n",
        "      unit weights, and then returns the resulting \n",
        "      feature maps output tensor.\n",
        "    '''\n",
        "    \n",
        "    dummy_input = torch.tensor(\n",
        "        [[list(range(h_in))]*w_in]*in_channels,\n",
        "        dtype=torch.float\n",
        "    ).unsqueeze(0) # Let's create an example input tensor like $(1, C_{in}, H. W)$\n",
        "\n",
        "    conv_layer = nn.Conv2d(\n",
        "        in_channels=in_channels,\n",
        "        out_channels=out_channels,\n",
        "        kernel_size=(kernel_size_h , kernel_size_w),\n",
        "        padding=(padding_h, padding_w),\n",
        "        stride=(stride_h, stride_w),\n",
        "        dilation=(dilation_h, dilation_w),\n",
        "        bias=False\n",
        "    ) # Creating an instance of the 2D convolution class with the given parameters.\n",
        "    \n",
        "    conv_layer.weight = nn.Parameter(torch.ones_like(conv_layer.weight)) # Replace randow weights to ones\n",
        "    output = conv_layer(dummy_input)\n",
        "    print('\\n\\nExample of input feature maps:')\n",
        "    plot_featuremaps(dummy_input,\n",
        "                     f'input featuremap tensor\\nshape = {dummy_input.shape}', \n",
        "                     v_max=h_in)\n",
        "\n",
        "    print(f'\\n\\nconv kernel shape is {conv_layer.weight.shape}\\n\\n')\n",
        "\n",
        "    print('Example of output feature maps:')\n",
        "    plot_featuremaps(output, \n",
        "                     f'output featuremap tensor\\nshape = {output.shape}')\n",
        "\n",
        "\n",
        "conv2d_example_interactive = interactive(\n",
        "    conv2d_example,\n",
        "    h_in=widgets.IntSlider(min=3, max=16, step=1, value=8),\n",
        "    w_in=widgets.IntSlider(min=3, max=16, step=1, value=8),\n",
        "    in_channels=widgets.IntSlider(min=1, max=4, step=1, value=3),\n",
        "    out_channels=widgets.IntSlider(min=1, max=4, step=1, value=2),\n",
        "    kernel_size_h=widgets.IntSlider(min=1, max=8, step=1, value=3),\n",
        "    kernel_size_w=widgets.IntSlider(min=1, max=8, step=1, value=3),\n",
        "    padding_h=widgets.IntSlider(min=0, max=8, step=1, value=0),\n",
        "    padding_w=widgets.IntSlider(min=0, max=8, step=1, value=0),\n",
        "    stride_h=widgets.IntSlider(min=1, max=8, step=1, value=1),\n",
        "    stride_w=widgets.IntSlider(min=1, max=8, step=1, value=1),\n",
        "    dilation_h=widgets.IntSlider(min=1, max=8, step=1, value=1),\n",
        "    dilation_w=widgets.IntSlider(min=1, max=8, step=1, value=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5HKxk-_qPdA"
      },
      "outputs": [],
      "source": [
        "display(conv2d_example_interactive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIGCyQ6lqPdA"
      },
      "source": [
        "## Использование свёрточных слоёв"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttXvD-NcqPdA"
      },
      "source": [
        "### Свёрточный слой = свёртка + активация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VcAxQN_qPdA"
      },
      "source": [
        "Поскольку операция свертки является линейной, аналогично полносвязному слою, к выходу сверточного слоя применяется* функция активации (например, ReLU).\n",
        "\n",
        ">*Так как функция активации применяется к тензору поэлементно, не важно, какую именно форму имеет тензор, а значит и какой слой находился передней ней: полносвязанный или сверточный. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFsqzZOdqPdA"
      },
      "outputs": [],
      "source": [
        "input = torch.randn((1, 3, 32, 32))\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "                           nn.Conv2d(in_channels=3,\n",
        "                                     out_channels=6,\n",
        "                                     kernel_size=3), # after conv shape: [1,6,30,30]\n",
        "                           nn.ReLU(), # Activation doesn't depend on input shape\n",
        "                           nn.Flatten(), # 6*30*30=5400\n",
        "                           nn.Linear(5400, 100), \n",
        "                           nn.ReLU(),  # Activation doesn't depend on input shape\n",
        "                           nn.Linear(100, 10) # 10 classes, like a cifar10\n",
        "                           )\n",
        "\n",
        "out = model(input)\n",
        "print(f'out shape: {out.shape}')\n",
        "print(f'out:\\n{out}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T9h6lrNqPdA"
      },
      "source": [
        ">Отметим, что внутри нейросети появляется новый слой - `nn.Flatten()`. Он необходим, поскольку полносвязанный слой принимает на вход набор векторов значений, тогда как свёрточный слой возвращает набор трёхмерных тензоров. `nn.Flatten()` необходим, чтобы преобразовать набор тензоров в набор векторов. Эту же операцию можно было бы выполнить с помощью метода `.view(-1)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GXrmrrSqPdA"
      },
      "source": [
        "### Общая структура свёрточной нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Jk1ih3qPdA"
      },
      "source": [
        "Нейросетевая модель из предыдущего примера позволяет в общем случае понять структуру свёрточных нейронных сетей: после некоторого количества свёрточных слоёв, извлекающих локальную пространственную информацию, идут полносвязанные слои (как минимум в количестве одного), сопоставляющие извлечённую информацию. \n",
        "\n",
        "Внутри свёрточных слоёв происходит следующий процесс: первые слои нейронных сетей имеют малые рецептивные поля, т.е. им соответствует малая площадь на исходном изображении. Такие нейроны могут активироваться лишь на некие простые шаблоны, по типу углов или освещённости.\n",
        " Активации уровнем выше уже имеют большие рецептивные поля, в результате чего в картах активации может сохраняться информация о более нетривиальных геометрических фигурах. С каждым слоем свёрточной нейронной сети рецептивные поля увеличиваются, увеличивается и сложность шаблонов, на которые может реагировать слой. В некоторых случаях, рецептивное поле нейронов может быть размером со всё исходное изображение. Пример можно увидеть на схеме ниже.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/receptive_field_size.png\" width=\"700\">\n",
        "\n",
        "Если изначально рецептивное поле имело размер $1\\times1$, то после свёртки фильтром $K\\times K$, оно стало иметь размер $K \\times K$. То есть, рецептивное поле каждого нейрона увеличилось на $K-1$ по каждому из направлений. Не сложно самостоятельно убедиться, что данная закономерность сохранится при дальнейшем применении фильтров того или иного размера.\n",
        "\n",
        "Однако, при больших размерах изображений (к примеру, $1024\\times1024$), нейронная сеть становится очень глубокой, что приводит к появлению большого количества параметров. Тем не менее, рецептивное поле каждого из нейронов растить нужно, что делается путём искусственного увеличения рецептивного поля каждого из элементов тензора. В принципе, это можно сделать двумя принципиально разными способами, о примере каждого из которых мы и поговорим:  \n",
        "1. Доработать операцию свёртки, чтобы рецептивное поле росло быстрее\n",
        "2. Добавить некую промежуточную операцию, которая бы увеличивала рецептивные поля"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee8pWyZOqPdA"
      },
      "source": [
        "### Шаг свёртки (Stride)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZQ3CBywqPdB"
      },
      "source": [
        "Вариантом доработки свёртки с целью увеличения рецептивного поля нейрона является изменение шага фильтра. Ранее фильтры двигались с шагом 1 по горизонтали и 1 по вертикали, то есть зоны применения фильтров были сдвинуты друг относительно друга на 1 строку либо столбец. При увеличении шага, количество применений фильтра изменяется. \n",
        "\n",
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_parameter_stride.gif\" width=\"350\"></center>\n",
        "<center>Свёртка массива $5\\times5$ фильтром размером $3\\times3$ с шагом $2$ по вертикали и горизонтали.</center>\n",
        "\n",
        "Казалось бы, с увеличением шага $S$ рецептивное поле не выросло - как увеличивалось с $1$ до $K$, так и увеличивается. Однако обратим внимание на иное: если раньше размерность $N$ становилась $N - F + 1$, то теперь она станет $\\displaystyle 1 + \\frac{N-F}{S}$. В результате, если раньше следующий фильтр с размером $K'$ имел рецептивное поле в $\\displaystyle N \\cdot \\frac{K'}{N'} = N \\cdot \\frac{K'}{N - F + 1}$, то теперь $\\displaystyle N \\cdot \\frac{K'}{N'} = N \\cdot \\frac{K'}{1 + \\frac{N-F}{S}}$. Понятно, что $\\displaystyle \\frac{K'}{N - F + 1} \\leq \\frac{K'}{1 + \\frac{N-F}{S}}$, потому рецептивное поле каждого нейрона увеличивается.\n",
        "\n",
        "При этом важно заметить, что в некоторых случаях часть данных может не попасть в свёртку. К примеру, при $N = 7,\\, K = 3,\\, S = 3$. В данном случае, $\\displaystyle N' = 1 + \\frac{7 - 3}{3} = 2\\frac13.$ В подобных ситуациях часть изображения не захватывается, в чём мы можем убедиться на наглядном примере:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSoFJiWPqPdB"
      },
      "outputs": [],
      "source": [
        "# Create torch tensor 7x7\n",
        "input = torch.tensor([[[[1, 1, 1, 1, 1, 1, 99],\n",
        "                        [1, 1, 1, 1, 1, 1, 99],\n",
        "                        [1, 1, 1, 1, 1, 1, 99],\n",
        "                        [1, 1, 1, 1, 1, 1, 99],\n",
        "                        [1, 1, 1, 1, 1, 1, 99],\n",
        "                        [1, 1, 1, 1, 1, 1, 99],\n",
        "                        [1, 1, 1, 1, 1, 1, 99]]]], dtype=torch.float)\n",
        "\n",
        "print(f'input shape: {input.shape}')\n",
        "\n",
        "conv = torch.nn.Conv2d(in_channels=1, # Number of channels\n",
        "                       out_channels=1, # Number of filters\n",
        "                       kernel_size=3, \n",
        "                       stride=3,\n",
        "                       bias=False # Don't use bias\n",
        "                       )\n",
        "conv.weight  = torch.nn.Parameter(torch.ones((1, 1, 3, 3))) # Replace randow weights to ones\n",
        "out = conv(input) \n",
        "\n",
        "print(f'out shape: {out.shape}')\n",
        "print(f'out:\\n{out}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYCLMApIqPdB"
      },
      "source": [
        "### Уплотнение (Субдискретизация, Pooling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gNe4SoGqPdB"
      },
      "source": [
        "Другим вариантом стремительного увеличения размера рецептивного поля является использование дополнительных слоёв, требующих меньшее количество вычислительных ресурсов. Слои субдискретизации прекрасно выполняют эту функцию - подобно свёртке, производится разбиение изображения на небольшие сегменты, внутри которых выполняются операции, не требующие использования обучаемых весов. Два популярных примера подобных операций: получение максимального значения (max pooling) и получение среднего значения (average pooling). \n",
        "\n",
        "\n",
        "Аналогично разбиению на сегменты при свёртке, слои пуллинга имеют два параметра: размер фильтра $F$ (то есть, каждого из сегментов) и шаг $S$ (stride). Аналогично свёрткам, при применении пуллинга, формула размера стороны будет $\\displaystyle N' = 1+ \\frac{N-F}{S}.$\n",
        "\n",
        "Ниже приведён пример использования обоих пуллингов при обработке массива.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/subdiscretization_pooling.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6XpCsr9qPdB"
      },
      "source": [
        "Реализуем это в коде:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJqXyGtcqPdB"
      },
      "outputs": [],
      "source": [
        "# create tensor 4x4\n",
        "input = torch.tensor([[[\n",
        "                     [1, 1, 2, 4],\n",
        "                     [5, 6, 7, 8],\n",
        "                     [3, 2, 1, 0],\n",
        "                     [1, 2, 3, 4],\n",
        "                     ]]], dtype=torch.float)\n",
        "\n",
        "max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "avg_pool = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "print(\"Input:\\n\", input)\n",
        "print(\"Max pooling:\\n\", max_pool(input))\n",
        "print(\"Average pooling:\\n\", avg_pool(input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbGQhTLrqPdB"
      },
      "source": [
        "**Важно отметить**, что, в отличие от свёрток, pooling выполняется по каждому из каналов отдельно, в результате чего количество каналов не меняется, в отличие от применения фильтра при свёртке. К примеру, ниже можно увидеть визуализация применения max pooling к одному из каналов тензора, имеющего $64$ канала. \n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/changing_size_of_image_after_pooling.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDvBbS5eqPdB"
      },
      "source": [
        "### Свёртка фильтром $1\\times1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiwq8s5NqPdB"
      },
      "source": [
        "Оба упомянутых выше метода позволяют сделать архитектуру сети не слишком глубокой, путём быстрого увеличения рецептивного поля нейронов, что позволяет уменьшить число обучаемых обучаемых параметров модели. Познакомимся с ещё одним способом уменьшения числа обучаемых параметров модели. \n",
        "\n",
        "\n",
        "Рассмотрим фрагмент архитектуры CNN, состоящий из одного свёрточного слоя с размерами ядра свёртки $F_h\\times F_w$ и некоторой активации (например, [`torch.nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)):\n",
        "\n",
        "\n",
        "$$... \\rightarrow (N, C_{in}, H, W) \\rightarrow \\text{conv2d}_{F_h\\times F_w} \\rightarrow \\text{ReLu} \\rightarrow  (N, C_{out}, H', W')  \\rightarrow ... $$\n",
        "\n",
        "Так как обучаемыми параметрами являются элементы ядра свёртки и сдвиг (bias), число таких параметров очень легко посчитать:\n",
        "* для формирования одной выходной карты признаков, как мы уже подробно обсуждали выше, нам нужно свернуть все входные карты признаков с соответствующими им матрицами элементов ядра свёртки, сложить результаты вместе и добавить bias — то есть в формировании одной выходной карты признаков участвуют $C_{in} \\cdot F_{h} \\cdot F_w + 1$ обучаемых параметров.\n",
        "* чтобы получить $C_{out}$ выходных карт признаков, мы столько  же раз должны повторить описанную выше процедуру с разными $C_{in} \\cdot F_{h} \\cdot F_w + 1$  параметрами.\n",
        "Таким образом, **общее число обучаемых параметров в одном свёрточном слое:** $\\text{n_params}[\\text{conv2d}_{F_h \\times F_w}] = (C_{in} \\cdot F_{h} \\cdot F_w + 1) \\cdot C_{out}$\n",
        "\n",
        "\n",
        "Теперь мы можем значительно уменьшить число обучаемых параметров, внеся небольшое изменение в рассмотренную архитектуру. Перед применением свёрточного слоя с размером ядра $F_h \\times F_w$ мы можем расположить ещё один свёрточный слой с ядром свёртки из одного единственного пространственного элемента ($1 \\times 1$), который будет предназначен для уменьшения числа карт признаков перед подачей последующему свёрточному слою без изменениям из пространственных размеров $H$ и $W$:\n",
        "\n",
        "$$... \\rightarrow (N, C_{in}, H, W)  \\rightarrow \\text{conv2d}_{1 \\times 1} \\rightarrow \\text{ReLu} \\rightarrow (N, C_{mid}, H, W) \\rightarrow \\\\ \\rightarrow (N, C_{mid}, H, W) \\rightarrow \\text{conv2d}_{F_h\\times F_w} \\rightarrow \\text{ReLu} \\rightarrow  (N, C_{out}, H', W')  \\rightarrow ... $$\n",
        "\n",
        "Идея заключается в следующем: рассматривая набор входных карт признаков  $C_{in} \\times (H \\times W)$ можно выделить вектор размерностью $C_{in}$, содержащий элементы карт признаков с некоторыми фиксированным пространственными координатами. Элементы этого вектора сообщают, насколько сильно рецептивное поле соответствует каждому из $C_{in}$ шаблонов. Применение к входным картам признаков свёрточного слоя с ядром $1 \\times 1 $ и последующей активации, приведёт к нелинейному преобразованию таких векторов из пространства размерности $C_{in}$ в новое пространство размерности $C_{mid}$. Так как параметры такого сжимающего преобразования будут подбираться в процессе обучения, мы ожидаем что свёртка $1 \\times 1$ позволит подобрать полезные комбинации входных карт признаков для всех пространственных элементов.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/1_times_1_convolutions_featere_maps.png\" width=\"600\">\n",
        "\n",
        "Если выбрать $C_{min} < C_{in}$, то общие число параметров модели действительно уменьшится:\n",
        "\n",
        "$$ \\text{n_params}[\\text{conv2d}_{1 \\times 1} \\rightarrow \\text{conv2d}_{F_h \\times F_w}] = \\\\\n",
        "= (C_{in} + 1) \\cdot C_{mid} + (C_{mid} \\cdot F_{h} \\cdot F_w + 1) \\cdot C_{out} \\approx \\frac{C_{mid}}{C_{in}}  \\text{n_params}[\\text{conv2d}_{F_h \\times F_w}] $$\n",
        "\n",
        "\n",
        "Ниже приведён пример применения такого фильтра с целью снижения количества карт признаков.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_with_kernel_size_one.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5YFCOIzqPdC"
      },
      "outputs": [],
      "source": [
        "conv = torch.nn.Conv2d(in_channels=128, # Number of input channels\n",
        "                       out_channels=32, # Number of filters\n",
        "                       kernel_size=1)\n",
        "\n",
        "input = torch.randn((1, 128, 64, 64))\n",
        "out = conv(input)\n",
        "\n",
        "print(\"Input shape:\", input.shape)\n",
        "print(\"Shape after 1x1 conv:\", out.shape) # [1, 32, 64, 64] batch, C_out, H_out, W_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl1u5QdOqPdC"
      },
      "source": [
        "### Сравнение свёрточного и полносвязанного слоев \n",
        "\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_layer.png\" width=\"550\">\n",
        "\n",
        "Мы успели довольно подробно рассмотреть свёрточный слой и заметить большое количество его сходств с полносвязным слоем (перцептроном). Теперь давайте попробуем сравнить эти два слоя по требуемому количеству параметров и операций умножения.  \n",
        "\n",
        "В первую очередь, давайте определимся с размерами входного и получаемого тензоров. Пусть на вход передаётся $C_{in}\\times H_{in}\\times W_{in}$. На выходе пусть будет $K$ нейронов для полносвязного слоя и $C_{out}\\times H_{out} \\times W_{out}$ для свёрточного слоя (фильтр имеет размер $C_{in} \\times F_1 \\times F_2$). $F_1$ и $F_2$ - размер ядра свёртки по высоте и ширине, соответственно.\n",
        "\n",
        "Для простоты расчётов давайте примем, что шаг фильтра равен $1$ как по горизонтали, так и по вертикали. В таком случае, $H_{out} = H_{in} - F_1 + 1$, а $W_{out} = W_{in} - F_2 + 1$.\n",
        "  \n",
        "##### Количество параметров:  \n",
        "***Полносвязанный слой:***  \n",
        "Данный слой требует по параметру (весу) для всех связей между входными и выходными нейронами, то есть $C_{in} \\cdot H_{in} \\cdot W_{in} \\cdot K$. Помимо этого, каждый из выходных нейронов имеет свободный член, общее количество которых $K$. Итого, количество обучаемых параметров: $(C_{in} \\cdot H_{in} \\cdot W_{in} + 1) \\cdot K$.\n",
        "\n",
        "***Свёрточный слой:***  \n",
        "Для свёрточного слоя параметры связаны лишь с ядрами свёртки - внутри каждого ядра находятся $C_{in} \\cdot F_1 \\cdot F_2$ параметров, общее их количество - $C_{out}$. Помимо этого, каждое из ядер имеет свой собственный свободный член, потому общее количество обучаемых параметров: $(C_{in} \\cdot F_1 \\cdot F_2 + 1) \\cdot C_{out}$.\n",
        "\n",
        "***Сравнение количества параметров:***  \n",
        "Поскольку количество свободных членов мало относительно количества весов, мы опустим их в этих расчётах. \n",
        "$$Comp_{param} = \\frac{C_{in} \\cdot H_{in} \\cdot W_{in} \\cdot K}{C_{in} \\cdot F_1 \\cdot F_2 \\cdot C_{out}} = \\frac{H_{in} \\cdot W_{in} \\cdot K}{F_1 \\cdot F_2 \\cdot C_{out}}.$$  \n",
        "\n",
        "\n",
        "##### Количество умножений: \n",
        "***Полносвязанный слой:***  \n",
        "В данном слое каждый вес используется лишь один раз, в результате общее количество умножений - $C_{in} \\cdot H_{in} \\cdot W_{in} \\cdot K$.  \n",
        "\n",
        "***Свёрточный слой:***\n",
        "Заметим, что в отличие от перцептрона, свёрточная нейронная сеть использует каждый вес несколько раз, а именно - при подсчёте каждого из элементов карты активации. Размер карты активаций: $H_{out} \\times W_{out}$. В итоге оказывается, что операция умножения применяется $C_{in} \\cdot F_1 \\cdot F_2 \\cdot C_{out} \\cdot H_{out} \\cdot W_{out}$.\n",
        "\n",
        "***Сравнение количества умножений:***\n",
        "$$Comp_{mult} = \\frac{C_{in} \\cdot H_{in} \\cdot W_{in} \\cdot K}{C_{in} \\cdot F_1 \\cdot F_2 \\cdot C_{out} \\cdot H_{out} \\cdot W_{out}} = \\frac{H_{in} \\cdot W_{in} \\cdot K}{F_1 \\cdot F_2 \\cdot C_{out} \\cdot H_{out} \\cdot W_{out}} = \\frac{Comp_{param}}{H_{out} \\cdot W_{out}}.$$\n",
        "\n",
        "##### Выводы:\n",
        "\n",
        "Заметим, что выигрыш по количеству параметров при использовании свёрточного слоя омрачается большим количеством операций перемножения. Это было проблемой в течение долгого времени, пока вычисление операции свёртки не перевели на видеокарты (Graphical Processing Unit). При выполнении свёртки одного сегмента не требуется информация о результатах свёртки на другом сегменте, потому чисто теоретически можно выполнять данные операции параллельно, с чем как раз прекрасно справляются видеокарты. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We0saD6tqPdC"
      },
      "source": [
        "#### Другие виды сверток\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PD6w1lcqPdC"
      },
      "source": [
        "##### 1D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMDyjReiqPdC"
      },
      "source": [
        "Одномерная операция свертки используется для данных, имеющих последовательную структуру - текстов, аудиозаписей, цифровых сигналов. Как правило, такую структуру можно представить в виде изменения величины с течением времени."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt37luSlqPdC"
      },
      "source": [
        "В pytroch одномерная свертка задается полностью аналогично двумерной: [torch.nn.Conv1d](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8suIeWb8qPdC"
      },
      "source": [
        "```\n",
        "torch.nn.Conv1d(in_channels,\n",
        "                out_channels, \n",
        "                kernel_size, \n",
        "                stride=1, \n",
        "                padding=0, \n",
        "                dilation=1,\n",
        "                groups=1, \n",
        "                bias=True, \n",
        "                padding_mode='zeros')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnijA0__qPdD"
      },
      "outputs": [],
      "source": [
        "conv = nn.Conv1d(16, 33, 3, stride=2)\n",
        "input = torch.randn(20, 16, 50)\n",
        "output = conv(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKaaoPwHqPdD"
      },
      "source": [
        "##### 3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0mr58hsqPdD"
      },
      "source": [
        "Двумерная операция свертки, о которой мы много говорили, применяется для обработки данных, имеющих пространственную структуру - то есть, играют роль взаимные расположения по двум осям. Совсем не обязательно, чтобы эти оси соответствовали высоте и ширине картинки. Например, одна ось может соответствовать координате сенсора в одномерной матрице, а вторая - времени получения информации с него.\n",
        "\n",
        "Трёхмерная операция свертки используется, когда данные имеются три независимых \"пространственных\" компоненты. Простейшим примером являются видео: к двумерной структуре самих изображений добавляется координата времени."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXQz822hqPdD"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/3d_convolution.png\" width=\"600\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OErf9W5rqPdD"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        " torch.nn.Conv3d(in_channels, \n",
        "                  out_channels, \n",
        "                  kernel_size, \n",
        "                  stride=1, \n",
        "                  padding=0, \n",
        "                  dilation=1, \n",
        "                  groups=1, \n",
        "                  bias=True, \n",
        "                  padding_mode='zeros')\n",
        " \n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT3KVl3pqPdD"
      },
      "outputs": [],
      "source": [
        "# With cubic kernels and same stride\n",
        "conv = nn.Conv3d(in_channels=16, \n",
        "                 out_channels=33, \n",
        "                 kernel_size=3, \n",
        "                 stride=2)\n",
        "\n",
        "# non-square kernels with unequal stride and padding\n",
        "conv = nn.Conv3d(in_channels=16, \n",
        "                 out_channels=33, \n",
        "                 kernel_size=(3, 5, 2), \n",
        "                 stride=(2, 1, 1),\n",
        "                 padding=(4, 2, 0))\n",
        "\n",
        "input = torch.randn(20, 16, 10, 50, 100)\n",
        "out = conv(input)\n",
        "\n",
        "print('out shape: ',out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p3TFGYSqPdD"
      },
      "source": [
        "#### Дополнительные материалы по сверткам"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDCSrdrJqPdD"
      },
      "source": [
        "[A guide to convolution arithmetic for deep\n",
        "learning](https://arxiv.org/pdf/1603.07285v1.pdf) \n",
        "\n",
        "[An Introduction to different Types of Convolutions in Deep Learning](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d)\n",
        "\n",
        "\n",
        "[A Comprehensive Introduction to Different Types of Convolutions](https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQiauRXiqPdD"
      },
      "source": [
        "## Пример сверточной сети\n",
        "\n",
        "Теперь мы можем более детально взглянуть на типичную архитектуру свёрточной нейронной сети. Как ранее уже обсуждалось, в первую очередь необходимо последовательностью свёрточных слоёв и уплотнений достичь того, чтобы каждый элемент карты активации имел большое рецептивное поле, а значит, мог отвечать за большие и сложные шаблоны. Затем данные карты активаций выпрямляются в вектора и передаются в полносвязанные слои, последовательность которых, используя глобальную информацию, возвращает значение целевой переменной.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/neural_network_architecture.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQKC4pMmqPdD"
      },
      "source": [
        "#### LeNet\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/lenet_architecture.png\" width=\"900\">\n",
        "\n",
        "Примером сети построенной по такой архитектуре является LeNet.\n",
        "Была разработана в 1989г [Яном Ле Куном](https://en.wikipedia.org/wiki/Yann_LeCun). Сеть имела 5 слоев с обучаемыми весами, из них 2 сверточных.\n",
        "\n",
        "Применялась в США для распознавания рукописных чисел на почтовых конвертах до начала 2000г.\n",
        "\n",
        "[LeNet torch documentation](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)\n",
        "\n",
        "Ниже представлена реализация подобной сети на Pytorch для датасета MNIST:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ns8fZxVqPdD"
      },
      "source": [
        "Загрузим датасет:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h36KN7V3qPdD"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# transforms for data\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "train_set = MNIST(root='./MNIST', train=True, download=True, transform=transform)\n",
        "test_set = MNIST(root='./MNIST', train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgH-LvvYqPdE"
      },
      "source": [
        "Напишем сверточную сеть:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEue_yWZqPdE"
      },
      "outputs": [],
      "source": [
        "class CNN_model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN_model, self).__init__()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), # входной канал=1 (изображение ч.б), на выходе 32 фильтра, размер ядра свертки 3x3, паддинг 1\n",
        "            nn.MaxPool2d(2), # size [32,14,14]\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1), # in channel=32, out=32\n",
        "            nn.MaxPool2d(2), # size [32,7,7]\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32*7*7, 100), # размерность на входе линейного слоя = количество_каналов*высота*ширина\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.conv_stack(x) \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f3owHRDqPdE"
      },
      "source": [
        "Запустим обучение:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jAc4rCaqPdE"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # change run time to gpu to fast training\n",
        "\n",
        "model = CNN_model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "loss_hist = [] # для графика\n",
        "for epoch in range(num_epochs):\n",
        "    hist_loss = 0\n",
        "    for _, batch in enumerate(train_loader, 0): # get batch\n",
        "        # обрабатываем batch \n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        # Зануляем градиенты\n",
        "        optimizer.zero_grad() \n",
        "        # получаем выходы сети\n",
        "        y_pred = model(imgs) \n",
        "        # вычисляем loss\n",
        "        loss = criterion(y_pred, labels)\n",
        "        # вычисляем градиенты\n",
        "        loss.backward() \n",
        "        # выполняем один шаг оптимизатора (обновляем параметры сети)\n",
        "        optimizer.step()\n",
        "        hist_loss += loss.item()\n",
        "    loss_hist.append(hist_loss / len(train_loader))\n",
        "    print(f\"Epoch={epoch} loss={loss_hist[epoch]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb30RnDNqPdE"
      },
      "source": [
        "Построим график обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frjhkpcRqPdE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(num_epochs), loss_hist)\n",
        "plt.xlabel(\"Epochs\", fontsize=15)\n",
        "plt.ylabel(\"Loss\", fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7PW5ARBqPdE"
      },
      "source": [
        "Давайте посчитаем accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll3U7g1lqPdE"
      },
      "outputs": [],
      "source": [
        "def calaculate_accuracy(model, data_loader):\n",
        "    correct, total = 0, 0 \n",
        "    with torch.no_grad(): \n",
        "        for batch in data_loader: # get batch\n",
        "            imgs, labels = batch # parse batch\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            y_pred = model.forward(imgs) # get output\n",
        "            _, predicted = torch.max(y_pred.data, 1) # get predicted class\n",
        "            total += labels.size(0) # all examples\n",
        "            correct += (predicted == labels).sum().item() # correct predictions \n",
        "    return correct / total "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aez4sFfYqPdE"
      },
      "outputs": [],
      "source": [
        "acc_train = round(calaculate_accuracy(model, train_loader), 3)\n",
        "print(f\"Accuracy train = {acc_train}\")\n",
        "acc_test = round(calaculate_accuracy(model, test_loader), 3)\n",
        "print(f\"Accuracy test = {acc_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJN0yXAUqPdE"
      },
      "source": [
        "Если мы сравним результат с моделью, для которой мы использовали только полносвязные слои, то можем увидеть, как выросла точность и уменьшилась ошибка на обучении (точность выросла на ~10%, ошибка уменьшилась с 0.4 до ~ 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 2!**  Дополните архитектуру нейросети. Вставьте еще один сверточный слой с количеством фильтров 32, далее макспулинг и функция активации ReLU (подсказка: размерности последующих слоев уменьшаться). В качестве ответа принимается значение **Accuracy test**.\n"
      ],
      "metadata": {
        "id": "_XAxbaT7Yp9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_model_big(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN_model_big, self).__init__()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), # входной канал=1 (изображение ч.б), на выходе 32 фильтра, размер ядра свертки 3x3, паддинг 1\n",
        "            nn.MaxPool2d(2), # size [32,14,14]\n",
        "            nn.ReLU(),\n",
        "            #вставьте еще один сверточный слой с количеством фильтров 32, далее макспулинг и функция активации ReLU (подсказка: размерности последующих слоев уменьшаться)\n",
        "            #\n",
        "            #\n",
        "            #\n",
        "\n",
        "\n",
        "            nn.Conv2d(32, 32, 3, padding=1), # in channel=32, out=32\n",
        "            nn.MaxPool2d(2), # size [32,7,7]\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32*7*7, 100), # размерность на входе линейного слоя = количество_каналов*высота*ширина\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.conv_stack(x) \n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # change run time to gpu to fast training\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "model = CNN_model_big().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "loss_hist = [] # for plotting\n",
        "for epoch in range(num_epochs):\n",
        "    hist_loss = 0\n",
        "    for _, batch in enumerate(train_loader, 0): # get batch\n",
        "        # обрабатываем batch \n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        # Зануляем градиенты\n",
        "        optimizer.zero_grad() \n",
        "        # получаем выходы сети\n",
        "        y_pred = model(imgs) \n",
        "        # вычисляем loss\n",
        "        loss = criterion(y_pred, labels)\n",
        "        # вычисляем градиенты\n",
        "        loss.backward() \n",
        "        # выполняем один шаг оптимизатора (обновляем параметры сети)\n",
        "        optimizer.step()\n",
        "        hist_loss += loss.item()\n",
        "    loss_hist.append(hist_loss / len(train_loader))\n",
        "    print(f\"Epoch={epoch} loss={loss_hist[epoch]:.4f}\")\n",
        "\n",
        "acc_train = round(calaculate_accuracy(model, train_loader), 3)\n",
        "print(f\"Accuracy train = {acc_train}\")\n",
        "acc_test = round(calaculate_accuracy(model, test_loader), 3)\n",
        "print(f\"Accuracy test = {acc_test}\")"
      ],
      "metadata": {
        "id": "1Ri0mZ9PYpQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно попробовать загрузить свое изображение и проверить, насколько хорошо будет работать обученный классификатор на новых данных. Можете нарисовать в графическом редакторе изображение цифры (желательно, чтобы изображение было квадратным)."
      ],
      "metadata": {
        "id": "mi5dbV7xEx3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() #Загрузим файл с изображением"
      ],
      "metadata": {
        "id": "dtbQM-AMFMmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "img_upl = Image.open(list(uploaded.keys())[0]) #откроем изображение\n",
        "transform = transforms.Compose([transforms.Resize((28, 28)), #конвертируем в размер 28 на 28 пикселей\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "tensor = transforms.functional.rgb_to_grayscale(transform(img_upl)) #переводим в ч.б. изображение\n",
        "tensor = transforms.functional.invert(tensor)\n",
        "\n",
        "pred = model(tensor.unsqueeze(0).to(device)).cpu().detach() #получим выход с сети на нашей картинке\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (4, 4)\n",
        "plt.imshow(tensor.cpu().squeeze(),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "digits = np.argmax(pred.numpy(), axis=1)\n",
        "print(pred)\n",
        "print('Предсказанный класс: ', digits)"
      ],
      "metadata": {
        "id": "N6-Pca-6FOfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKELu2T5qPdE"
      },
      "source": [
        "# 5. Визуализация\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTzjQ6sqqPdE"
      },
      "source": [
        "Нам может быть интересно, на какую информацию обращает внимание модель в процессе работы, на какие визуальные шаблоны реагирует, насколько они интерпретируемы? \n",
        "\n",
        "Чтобы ответить на все эти вопросы, можно визуализировать карты активаций и веса фильтров свёртки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D16LTFIRqPdE"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/what_hidden_layers.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh5G5hK3qPdE"
      },
      "source": [
        "## Визуализация весов \n",
        "\n",
        "Веса фильтров на первом слое легко визуализировать. И результат легко интерпретируется, так как у фильтров такое же количество каналов, как и у цветных изображений (3).\n",
        "\n",
        "Ниже приведен пример того, как это можно сделать для обученной модели в Pytorch (Alexnet)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTSXABlXqPdF"
      },
      "source": [
        "Чтобы понять, через какие свойства можно получить доступ к весам, выведем структуру модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTUMcPddqPdF"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "alexnet = models.alexnet(weights='AlexNet_Weights.DEFAULT') \n",
        "print(alexnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac1r0HmkqPdF"
      },
      "source": [
        "Видно, что первый слой это 0-й элемент контейнера features.\n",
        "Веса хранятся в weight.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej_7F_coqPdF"
      },
      "outputs": [],
      "source": [
        "weight_tensor = alexnet.features[0].weight.data # extract weights\n",
        "print('Weights shape', weight_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POiBVHLAqPdF"
      },
      "source": [
        "Чтобы отобразить все веса на одном изображении воспользуемся вспомогательной функцией [make_grid](https://pytorch.org/vision/stable/utils.html#torchvision.utils.make_grid) из [torchvision.utils](https://pytorch.org/vision/stable/utils.html)\n",
        "\n",
        "На вход метод получает batch изображений (B x C x H x W) в формате torch.tensor и визуализирует их в виде таблице. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEoQXHoSqPdF"
      },
      "outputs": [],
      "source": [
        "from torchvision import utils\n",
        "\n",
        "img_grid = utils.make_grid((weight_tensor + 1) / 2, pad_value=1) # combine weights from all channel into table, note remapping to (0,1) range\n",
        "print(\"Output is CxHxW image\", img_grid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-DJyDfQqPdF"
      },
      "source": [
        "Ее часто используют, чтобы отображать изображения в tensorboard \n",
        "\n",
        "А чтобы отобразить получившуюся таблицу в блокноте средствами matplotlib, нам потребуется поменять порядок хранения данных, поместив каналы на первое место."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b0TpGTcqPdF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
        "plt.imshow(np.transpose(img_grid, (1, 2, 0))) # change channel order for compability with numpy & matplotlib\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCMuMdT9qPdF"
      },
      "source": [
        "Видно, что модель научились улавливать простые геометрические формы - края под разными углами, точки того или иного цвета. Тем не менее, фильтры AlexNet'а оказались настолько большими, что частично захватили не только простую локальную информацию, но и сложные градиенты или решётки.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfcRx01nqPdF"
      },
      "source": [
        "### Визуализация фильтров промежуточных слоев\n",
        "\n",
        "К сожалению, выполнить ту же операцию для фильтров на скрытых слоях едва ли представляется разумным - в отличие от принятого трёхканального вида фильтров, который легко можно трактовать и визуализировать, фильтры поздних слоёв имеют гораздо больше каналов, что делает их удобное отображение практически невозможным. Пожалуй, единственным вариантом отображения является поканальное отображение весов, которое довольно сложно трактовать, в чём можно убедиться, взглянув на пример ниже.\n",
        "\n",
        "\n",
        "**Higher Layer: Visualize Filter**\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L06/weight_visualization.png\" width=\"700\">\n",
        "\n",
        "<center><p><em>Source: <a href=\"https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html\">ConvNetJS CIFAR-10 example</a></p> </em></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR1-BlxJqPdF"
      },
      "source": [
        "Визуализируем веса 2-го сверточного слоя AlexNet. \n",
        "Слой доступен через `features[3] `"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bag8xsdRqPdF"
      },
      "outputs": [],
      "source": [
        "weights_of_conv2_layer = alexnet.features[3].weight.data # extract weights\n",
        "print(weights_of_conv2_layer.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrbMVoVuqPdG"
      },
      "source": [
        "В нем 192 фильтра в каждом 64 ядра. Поэтому ограничимся первым фильтром и выведем все его ядра."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pDAURWDqPdG"
      },
      "outputs": [],
      "source": [
        "first_filter_kernels =  weights_of_conv2_layer[0]\n",
        "print(first_filter_kernels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t9fyeomqPdG"
      },
      "source": [
        "Чтобы использовать image_grid входной тензор должен иметь формат BxCxHxW.  Поэтому добавим размерность соответствующую каналам:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNv91kZbqPdG"
      },
      "outputs": [],
      "source": [
        "img_grid = utils.make_grid(\n",
        "    weights_of_conv2_layer[0].unsqueeze(1), # add fake channel dim\n",
        "    pad_value=1)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 16)\n",
        "plt.imshow(np.transpose((img_grid + 1) / 2, (1, 2, 0))) # change channel order for compability with numpy\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg2aZG8CqPdG"
      },
      "source": [
        "Интерпретация такой визуализации довольно затруднительна, зато мы разобрались, как получать доступ к весам."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpCfvRkmqPdG"
      },
      "source": [
        "## Визуализация карт активаций\n",
        "\n",
        "Наиболее очевидный метод визуализации заключается в том, чтобы показать активации сети во время прямого прохода. Для сетей ReLU активации обычно начинают выглядеть относительно сгущенными и плотными, но по мере развития обучения активации обычно становятся более редкими и локализованными. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81cmC2ryqPdG"
      },
      "source": [
        "На последних слоях свёрточной нейронной сети размеры рецептивных полей нейронов становятся сравнимы с размером исходного изображения, потому при визуализации их карт активации становится понятно, какие нейроны реагируют на какие части изображений.\n",
        "\n",
        "К примеру, на изображении ниже активация выделенного нейрона достигнута благодаря пикселям, примерно соответствующим расположению лица человека, потому можно предположить, что он научился находить лица на изображении. Более подробно об этом можно почитать в статье [Understanding Neural Networks Through Deep Visualization](https://arxiv.org/abs/1506.06579).\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L06/visualization_activations.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O46uFf2GqPdG"
      },
      "source": [
        "В отличие от весов, карты активаций не сохраняются в памяти. Для того чтобы получить к ним доступ, в pytorch предусмотрен механизм под названием [Hooks](https://pytorch.org/tutorials/beginner/former_torchies/nnft_tutorial.html#forward-and-backward-function-hooks)\n",
        "\n",
        "Благодаря ему можно получить доступ к выходам или входам слоя, как при прямом, так и при обратном распространении сигнала через сеть.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOHGqzbtqPdG"
      },
      "source": [
        "Зарегистрируем свой hook. Он просто выведет в консоль размеры карты активации (выхода слоя).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZuSMCPHqPdG"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "def module_hook(module: nn.Module, input, output):  # For nn.Module objects only.\n",
        "    print(\"Hi, i am hook_1!\", output.shape) # activation_map\n",
        "\n",
        "handle = alexnet.features[10].register_forward_hook(module_hook) # attach hook to last conv layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TotATUibqPdG"
      },
      "source": [
        "Проверим, что он работает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q57GRruqPdG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "out = alexnet(torch.randn(1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oNApHGiqPdG"
      },
      "source": [
        "Чтобы удалить hook, используйте метод remove дескриптора, который возвращает метод register_forward_hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eynn36vvqPdG"
      },
      "outputs": [],
      "source": [
        "handle.remove()\n",
        "out = alexnet(torch.randn(1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PPYngJvqPdG"
      },
      "source": [
        "Вывода нет, hook отключился!\n",
        "\n",
        "Теперь напишем hook, который выведет нам карту активации. \n",
        "Так как на выходе данного слоя 256 каналов, выведем каждый отдельно, подав на вход make_grid тензор с 256 элементами. \n",
        "\n",
        "Для этого потребуется:\n",
        "* удалить batch измерение\n",
        "* добавить измерение, имитирующее канал для картинок\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXIwvFWVqPdH"
      },
      "outputs": [],
      "source": [
        "def module_hook(module: nn.Module, input, output):\n",
        "    #activation_map = output.squeeze(0).unsqueeze(1) # alternative solution\n",
        "    activation_map = output.permute(1, 0, 2, 3)\n",
        "    print(activation_map.shape)\n",
        "    img_grid = utils.make_grid(activation_map,pad_value=10,nrow = 16) \n",
        "    plt.rcParams[\"figure.figsize\"] = (12, 12)\n",
        "    plt.imshow(np.transpose(img_grid, (1, 2, 0))) # change channel order for compability with numpy\n",
        "    plt.show()\n",
        "\n",
        "handle = alexnet.features[10].register_forward_hook(module_hook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slAakLLWqPdH"
      },
      "source": [
        "\n",
        "\n",
        " \n",
        "\n",
        "Чтобы карта активаций  была интерпретируема, надо использовать реальное изображение. Загрузим его:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpWdI8hxqPdH"
      },
      "outputs": [],
      "source": [
        "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/L06/fox.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVrqLUjgqPdH"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img_fox = Image.open(\"fox.jpg\")\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
        "plt.imshow(img_fox)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ubMHqbHqPdH"
      },
      "source": [
        "Загрузим изображение, преобразуем в тензор и подадим на вход модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bZiB6GvqPdH"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((256, 256)),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "tensor = transform(img_fox)\n",
        "out = alexnet(tensor.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU6E0TlyqPdH"
      },
      "source": [
        "Тут уже можно увидеть некоторые паттерны. Видно, что многие фильтры реагируют на лисицу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxciZ28wqPdH"
      },
      "source": [
        "Единственная опасная ловушка, которую можно легко заметить с помощью этой визуализации, заключается в том, что некоторые карты активации могут быть равны нулю для многих различных входов. Это может указывать на мертвые фильтры и может быть симптомом высокой скорости обучения."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "XZEKq2q6pUss",
        "CLMJwafhpUss",
        "Bb09FU_bpUst",
        "elpZrN3bpUst",
        "q_Fz63MjpUst",
        "ZhqUAO_cpUsv",
        "HN7PuAKhpUsw",
        "-YQoDGRupUsw",
        "bX1jRHj2pUsz",
        "P5Ktyb50pUs0",
        "M2o7tSmRpUs0",
        "w-xtdTIspUs1",
        "tBSuVdq7pUs1",
        "YOZc3wrMpUs2",
        "u55hQo4ApUs3",
        "PPKMLDVtpUs3",
        "wCft2s4QpUs3",
        "oTdAdrSPpUs4",
        "tzMx_uzvpUs4",
        "kk-Bhe0ZpUs4",
        "qwfmweOKpUs5",
        "TnAa3YFppUs5",
        "D11FA_2FpUs6",
        "u3q5cbQipUs6",
        "qmf6Qk_0pUs6",
        "iftK0X-HqPcz",
        "psBeTR9FqPc0",
        "m95WwvIwqPc2",
        "mvndhXmAqPc3",
        "lLK-khPgqPc5",
        "ly5wJimGqPc5",
        "hVI_PWfBqPc8",
        "YZF22TShqPc9",
        "eYOhRSguqPc9",
        "aOGG5xm7qPc-",
        "roV2J2H_qPc-",
        "cUb_hOS0qPc-",
        "BvBZcgJFqPc_",
        "HIGCyQ6lqPdA",
        "ttXvD-NcqPdA",
        "4GXrmrrSqPdA",
        "ee8pWyZOqPdA",
        "XYCLMApIqPdB",
        "uDvBbS5eqPdB",
        "Rl1u5QdOqPdC",
        "We0saD6tqPdC",
        "7p3TFGYSqPdD",
        "HKELu2T5qPdE",
        "Xh5G5hK3qPdE",
        "vfcRx01nqPdF",
        "SpCfvRkmqPdG"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}